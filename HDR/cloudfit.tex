% !TeX spellcheck = fr_FR


\begin{resume}
	
	CloudFIT est un intergiciel pour le calcul distribué particulièrement conçu pour une exécution en environnements hétérogènes. Cette hétérogénéité peut assumer plusieurs formes parmi celles citées dans les chapitres précédents : \textbf{l'hétérogénéité matérielle}, \textbf{l'hétérogénéité des communications},\textbf{ l'hétérogénéité des tâches de calcul} et la \textbf{dynamicité des ressources}. En effet, CloudFIT peut être déployé sur un environnement pervasif composé de n{\oe}uds présentant des caractéristiques très diverses (allant des petits nano-ordinateurs jusqu'aux serveurs HPC). De plus, il supporte des tâches de calcul irrégulières selon le paradigme FIIT ainsi que des variantes où les tâches présentent un certain niveau de dépendance (DAGs, Map-Reduce, etc.).
%	\begin{description}
%		\item [l'hétérogénéité matérielle :] supporte différents types de n{\oe}uds de calcul, avec des spécifications allant des petits nano-ordinateurs jusqu'aux machines dédiées au calcul haute performance ;
%		\item [l'hétérogénéité de communication :] il est possible d'interconnecter des n{\oe}uds provenant de réseaux différents grâce à l'utilisation d'un \textit{overlay} pair-à-pair ;
%		\item [l'hétérogénéité de calcul :] supporte des tâches de calcul irrégulières selon le paradigme FIIT ainsi que des variantes où les tâches présentent un certain niveau de dépendance (DAGs, Map-Reduce) ;
%		\item [la dynamicité des ressources :] les n{\oe}uds peuvent subir des déconnexions ou des reconnexions, mais aussi voir varier leurs paramètres tels que la mémoire disponible.
%	\end{description}
%	
  
	Pour cela, CloudFIT repose sur un \textit{overlay} pair-à-pair (P2P) qui gère les aspects liés à l'interconnexion des n{\oe}uds, alors que les services CloudFIT s'occupent de la gestion des tâches de calcul. D'un point de vue structurelle, la spécification de CloudFIT est modulaire, offrant au concepteur la possibilité d'intervenir sur la totalité de la pile logicielle. Cette modularité non seulement garantit une indépendance vis-à-vis des bibliothèques existantes comme fait de CloudFIT une plateforme idéale pour le prototypage de nouvelles technologies dédiées à l'Internet des Objets (IoT), au \textit{big data}, aux environnements pervasifs et au \textit{fog computing}.
	
	CloudFIT a été initialement développé dans le cadre du projet STIC-AmSud PER-MARE, où il a été utilisé pour l'étude sur le déploiement d'une application \textit{big data} dans des environnements pervasifs. Au fil des années, son développement a pu bénéficier de multiples collaborations (avec l'Université Paris 1, par exemple) et aujourd'hui il est appliqué dans le cadre du projet international CAPES-Cofecub MESO, portant sur la physique de l'atmosphère.

	%CloudFIT est un intergiciel pour le calcul distribué reposant sur un \textit{overlay} P2P. D'un point de vue structurel, la spécification de CloudFIT a été faite pour reposer sur les services d'un \textit{overlay} P2P déjà existant plutôt que de faire toute la gestion des n{\oe}uds et de leur communication (ce qui était le cas avec son prédécesseur CONFIIT \cite{FKF03,Flauzac10}). Ceci a permis une indépendance vis-à-vis des bibliothèques existantes et garantit des propriétés de modularité et maintenance qui ont fait ses preuves au fil des années.
	
	%Un autre facteur important du succès de CloudFIT est qu'il supporte autant le paradigme FIIT (Finite number of Independent and Irregular Tasks), que des variantes où les tâches présentent une certaine dépendance (DAGs, Map-Reduce, etc.). Cela signifie que CloudFIT peut être utilisé comme plateforme d'exécution distribuée pour la plupart des applications capables de répartir le travail en un nombre fini de tâches. 
	
	%Au fil des années cette plateforme a été enrichie avec d'éléments tels que des ordonnanceurs sensibles au contexte ou des mécanismes de stockage DHT. La possibilité d'intervenir sur la totalité de la pile logicielle rend CloudFIT spécialement attractif en tant que plateforme expérimentale pour le prototypage,  et le test de techniques innovatrices. En effet, c'est un projet que je développe presque entièrement, de la spécification à l'implémentation des fonctionnalités. Grâce à CloudFIT, je peux orienter ma recherche en ce moment sur le \textit{fog computing} et l'Internet des Objets, deux thématiques que je tiens à c{oe}ur. 
	
	Dans ce chapitre nous allons présenter les éléments principaux de l'architecture de CloudFIT et les mécanismes liés à la gestion des n{oe}uds et des tâches, ainsi que des résultats obtenus jusqu'à présent. On discutera aussi des futures directions de recherche, notamment la mis en place d'un réseau multi-échelle pour le \textit{fog computing} ou des stratégies pour accélérer l'exécution d'applications \textit{big data}. 
	
	%CloudFIT a été initialement développé et utilisé dans le cadre du projet STIC-AmSud PER-MARE, et ceci est illustré grâce à une étude sur le déploiement d'un application \textit{big data} dans un environnement pervasif. Plus tard, nous avons utilisé CloudFIT pour d'autres applications, raison pour laquelle nous présentons un étude de cas avec le développement et exécution d'une application métier en physique de l'atmosphère, destinée à la surveillance les événements liés à la couche d'Ozone Antarctique.
	
	%Les travaux présentés dans cette partie ont souvent compté avec la collaboration de Manuele Kirsch Pinheiro, maître de conférences à l'Université Paris 1 Panthéon-Sorbonne. Ils englobent des activités menées pendant le projet PER-MARE, des études préparatoires à l'élaboration du projet CAPES-Cofecub MESO (2017-2020), portant sur la physique de l'atmosphère mais aussi des recherches spécifiques (adaptation au contexte, organisation multi-échelle pour le \textit{fog}, interfaces pour utilisation de CloudFIT en tant que PaaS, etc.).
	
	
	
\end{resume}

\section{Introduction}

Avec l'augmentation exponentielle du nombre de dispositifs informatiques de proximité (\textit{smartphones}, tablettes, nano-ordinateurs, etc.),  il est important de comprendre comment organiser ces ressources et comment gérer l'information dans ces environnements hétérogènes et dynamiques (que nous appellerons "environnements pervasifs"). 
En effet, notre vie quotidienne présente de plus en plus d'appareils connectés pour suivre notre santé et nos mouvements, la sécurité de nos maisons ou le stress hydrique de nos plantes et de nos cultures. 

De nos jours, les limitations majeures pour une utilisation orchestrée de ces dispositifs ne se trouve pas en leur capacité de calcul ou de communication (WiFi, \textit{Bluetooth}, etc.), mais surtout à la difficulté d'exploiter et de coordonner ces appareils. Heureusement, cette frontière est en train de tomber avec l'avènement de l'Internet des Objets (\textit{Internet of Things} - IoT). L'IoT représente une nouvelle tendance de l'industrie informatique où l'environnement physique est peuplé d'objets interconnectés et communicants, lesquels interagissent les uns avec les autres et avec l'environnement lui-même. La force de ce concept réside dans l'intégration transparente des capteurs, des actionneurs et d'autres dispositifs, ce qui permet la collecte et le traitement d'informations à grande échelle mais aussi la prise de décisions au plus proche des utilisateurs. À vrai dire, l'augmentation de la bande passante et de la puissance de calcul des appareils, couplés avec un coût décroissant de capteurs \cite{Jones2014}, nous permettent d'envisager des applications et des stratégies de traitement de données bien différentes de celles développées jusqu'à aujourd'hui.


En effet, la plupart des applications courantes repose sur un modèle client-serveur. Dans le cas des premières solutions IoT sur le marché, l'agrégation et l'analyse des données sont effectuées principalement sur des infrastructures déportées de type \textit{cloud computing}. Plusieurs travaux \cite{Miorandi2012, Gubbi2013, Fazio2015} comptent sur ces infrastructures car elles offrent autant la puissance de calcul que la flexibilité pour l'exécution de services et des applications \cite{Serrano2013}. Malgré ces avantages, les infrastructures de type \textit{cloud} ont aussi quelques inconvénients importants. En effet, comme nous avons vu en Chapitre \ref{chap:grids}, le transfert de données à longue distance peuvent induire des délais considérables et ralentir le traitement et la prise des décisions. En outre, les applications qui dépendent entièrement des services distants peuvent échouer si la connexion est défectueuse ou trop lente.

Par conséquent, nous devons repenser la façon de transmettre, de stocker et d'analyser les données dans ces environnements. Les architectures réseaux traditionnelles ne sont pas préparées pour l'hétérogénéité qui caractérise l'IoT (à la fois sur les capacités de calcul, de mémoire, d'autonomie et de communication), ni sont préparées pour la nature spontanée de leurs interactions. Cette préoccupation a conduit les chercheurs à développer une série de solutions alternatives au \textit{cloud computing}, telles que les \textit{grids} pervasifs \cite{Parashar2010}, le \textit{mobile edge computing} \cite {Dey2013,MEC,Satyanarayanan09}, le \textit{fog computing} \cite{Bonomi2012} ou bien le \textit{edge-centered computing} \cite{Lopez2015}. Toutes ces alternatives partagent un même objectif : utiliser la puissance de calcul des dispositifs environnants pour effectuer des tâches habituellement déléguées à une installation distante. 

La plateforme CloudFIT a été développé afin de fournir un support logiciel à ce type de calcul distribué mais surtout dans le but d'offrir un cadre expérimental où nous pouvons intervenir sur toute la pile logicielle et tester différents concepts issus de nos recherches. En effet, l'expérience passée avec des plates-formes de calcul distribué tiers (CONFIIT \cite{Flauzac10}, Apache Hadoop \cite{Hadoop,Steffenel13b}, etc.) nous fait prendre conscience de la complexité de ces systèmes et des limitations à leur  extension ou modification. Le fait de pouvoir spécifier, contrôler et modifier l'ensemble des composants de la plateforme offre des innombrables possibilités pour l'investigation de nouveaux concepts ou tous simplement pour l'adéquation à des nouveaux besoins. 
  
Dans les sections suivantes nous allons présenter les solutions architecturales et pratiques utilisées pour le développement de CloudFIT, des cas d'usage et aussi des directions de recherche pour l'avenir de cette plateforme.

\section{État de l'Art et Définitions}

La diffusion des dispositifs de proximité avec des capacités de calcul non-négligeables (\textit{smartphones}, tablettes, ordinateurs portables et nano-ordinateurs tels que le Raspberry Pi) encourage l'intégration de ces dispositifs dans le traitement des données, à l'opposé d'une approche purement "client-serveur" où tout le stockage et le traitement des données se fait sur un ou plusieurs serveurs distants (serveurs, \textit{clusters}, \textit{data centers}, infrastructures \textit{cloud}). C'est ainsi que des approches telles que les \textit{grids} pervasifs \cite{Parashar2010}, le \textit{mobile edge computing} \cite {Dey2013,MEC,Satyanarayanan09}, le \textit{edge-centered computing} \cite{Lopez2015} ou bien le \textit{fog computing} \cite{Bonomi2012} ont été proposées dans le but de placer certaines applications et services au plus près de l'utilisateur final.

Les travaux sur l'\textit{edge computing} et le \textit{fog computing} partagent souvent les mêmes définitions \cite{Vermesan}. En effet, le \textit{fog computing} a été défini par CISCO \cite{FogCISCO} comme "un paradigme qui étend le \textit{cloud computing} et ses services à la périphérie du réseau", tandis que le \textit{(mobile) edge computing} vise à transformer les stations de base proches en "centres de services intelligents capables de fournir des services hautement personnalisés" \cite{Vermesan}. 
Plus globalement, le \textit{fog computing} fait référence à une infrastructure décentralisée dans laquelle les ressources de calcul sont distribuées de manière intelligente sur des emplacements répondant au mieux aux besoins des applications, comme par exemple la latence des communications, la bande passante ou les besoins de confidentialité. En effet, le terme \textit{fog} (un brouillard) exprime l'idée que les services doivent se rapprocher et entourer les utilisateurs et les sources de données, au lieu de rester distant comme dans le cas des \textit{clouds}. La Figure \ref{fig:fog} représente une tentative de représentation conceptuelle de la relation entre l'IoT, le \textit{fog} et le \textit{cloud}. 


\begin{figure}
	\centering
	%\vspace{-0.3cm}
	\includegraphics[width=0.75\linewidth]{img/fog}
	%\vspace{-0.4cm}
	\caption{Architecture conceptuelle d'une infrastructure \textit{fog}/\textit{cloud} \cite{10.3389/fnhum.2014.00370}}\label{fig:fog}
\end{figure}

On retrouve plusieurs tentatives de spécifier l'organisation ce cette infrastructure. Des exemples de \textit{edge/fog} comprennent les services \textit{fog} \cite{Bonomi2012} et les \textit{cloudlets} \cite{Satyanarayanan09}, tous les deux proposant le déploiement des serveurs de proximité capables d'offrir des services avec une latence réduite. A quelques exceptions près, comme \cite{Dey2013}, ces travaux considèrent que les dispositifs IoT ne contribuent pas à l'effort de calcul, restant dépendants d'un service tiers (à proximité ou à distance).

Garcia Lopez et al. \cite{Lopez2015} explorent une autre facette de l'\textit{edge computing} en se concentrant sur le rôle de l'homme dans la boucle de contrôle. En effet, ces auteurs affirment la nécessité de recentrer le contrôle sur les équipements situés au bord du réseau, au lieu de simplement les considérer comme une première couche de calcul reliée à un réseau plus grand et plus puissant. %Ces auteurs donnent une attention particulière à l'interaction humaine, qui revient au centre des décisions. 
Malheureusement, dans cette définition, les dispositifs IoT ne contribuent pas non plus aux efforts de calcul, étant considérés comme des capteurs/actionneurs pilotés par les interactions entre l'homme et l'\textit{edge}.

Bien que ces travaux préconisent la nécessité d'un environnement informatique de proximité, ils oublient souvent de détailler l'interconnexion ou les exigences de coordination entre les processus. Cela est particulièrement nécessaire dans l'optique de l'IoT, qui impose des défis importants pour l'évolutivité, la dynamicité et l'hétérogénéité des ressources. 

Dans la littérature nous trouvons aussi la notion de \textit{grid} pervasif \cite{Parashar2010}, qui vise l'intégration des dispositifs de détection/d'actionnement ainsi que des systèmes de haute performance classiques. Ces \textit{grids} reposent sur l'utilisation des ressources habituellement sous-utilisés, composant ainsi une plateforme de calcul dynamique \cite{Steffenel2015Roma}. En effet, les \textit{grids} pervasifs offrent la possibilité d'intégrer les différentes ressources disponibles allant des petits appareils de type Raspberry Pi jusqu'aux machines virtuelles déployées sur les infrastructures d'un data-center. Pour l'Internet des Objets, les \textit{grids} pervasifs représentent une opportunité de déployer des tâches informatiques sur des ressources situées à proximité des dispositifs IoT, minimisant ainsi le transfert de données vers un réseau distant. De plus, selon les besoins, ces tâches peuvent être allouées aux ressources avec la capacité de calcul adéquate à chaque service, sans avoir à externaliser les données et les services.

Une caractéristique souvent avancée par les idéalisateurs des \textit{grids} pervasifs est leur indépendance par rapport à des architectures et des services opérateurs. Malgré l'appel à la décentralisation et à l'affranchissement du "tout \textit{cloud}" prôné par les premiers travaux sur l'\textit{edge computing} et le \textit{fog computing}, nous observons une appropriation de ces concepts par les grands opérateurs du marché tels que Cisco, Intel ou Microsoft. En effet, ceux-ci se sont réunis au sein de l'\textit{Open Fog Consortium}\footnote{\url{http://www.openfogconsortium.org/}} afin de créer une architecture de référence pour le \textit{fog computing}. Bien que de telles initiatives sont nécessaires pour la maturation d'une technologie, elles sont souvent source de contraintes. En effet, l'une de nos préoccupations lors du développement de CloudFIT est de le maintenir le plus léger possible, avec une dépendance logicielle réduite et une empreinte mémoire minimale afin de pouvoir le déployer sur le plus grand nombre de dispositifs, inclusive des nano-ordinateurs.

Finalement, afin de répondre aux différents besoins des architectures et applications IoT, nous pouvons explorer le concept des systèmes multi-échelle. Les \textit {systèmes multi-échelles} sont des systèmes distribués où les services sont organisés en couches à travers une ou plusieurs dimensions (dispositifs, réseau, localisation géographique, etc.), chaque couche fournissant un niveau de service supplémentaire qui peut être consulté en fonction du contexte de l'appareil \cite{Rottenberg2012,Rottenberg2014}.  En vertu de cette approche, des actions primaires peuvent être décidées/interprétées à proximité, tandis qu'une analyse plus poussée de l'information peut être effectuée par des serveurs externes. Cette analyse stratifiée peut également être utilisée pour renforcer les aspects liés à la vie privée comme, par exemple, l'anonymisation des données qui seront externalisés. Nous croyons que ce concept offre la granularité et les modalités d'interconnexion nécessaires à l'autonomie des dispositifs IoT et permet des services plus réactifs et de meilleure qualité car exécutés au plus près des dispositifs et des utilisateurs. Ceci est notamment utile dans des domaines tels que la domotique, où l'adaptation au contexte et le respect de la vie privée sont de facteurs clés.

La diversité de travaux autour du \textit{fog computing} n'est pas nécessairement suivie par une offre en outils ou en plateformes pour sa mise en {\oe}uvre. En effet, la plupart des auteurs cherchent encore la meilleure manière de déployer et de coordonner les n{\oe}uds dans des tels environnements. Bien que souvent cités, des approches basées sur la virtualisation \cite{Satyanarayanan09}, les \textit{micro-clouds} \cite{Elkhatib2017},  les micro-services \cite{Villari2016} ou les \textit{workflows} \cite{Hao2017} ne sont que des possibilités pour la mise en place du \textit{fog}. Comme remarqué par \textit{Yi et al.} \cite{Yi2015}, les challenges sont multiples et incluent aussi la gestion du réseau (via les \textit{Software Defined Network} - SDN- ou les \textit{overlays} P2P), le déploiement, l'orchestration, la migration de tâches/services, etc. L'absence de plates-formes vraiment dédiées au \textit{fog computing} peut s'expliquer par le manque de standardisation. Ceci pourra changer avec la publication des spécifications de l'\textit{Open Fog Consortium} (initialement prévue pour le début 2017 mais toujours pas publiées), mais, pour le moment, ces initiatives sont rares et limitées. Parmi les rares plates-formes opérationnelles dédiées au \textit{fog computing}, on peut citer IOx de Cisco \cite{IOx2017} et Paradrop \cite{Willis2014}. La plateforme de Cisco repose sur l'hébergement de machines virtuelles sur des routeurs et switches compatibles, et pour cela les utilisateurs disposent de APIs et scripts pour créer et déployer leurs propres images et applications. Malheureusement le code source de IOx est fermé, empêchant toute extension ou étude plus poussée. ParaDrop, de son côté, se base sur un réseau de passerelles (installés, par exemple, sur les points d'accès WiFi ou sur les box Internet à la maison), mais celles-ci doivent se connecter à des serveurs ParaDrop, ce qui empêche la décentralisation du \textit{fog}. 

Dans un souci de simplicité, par la suite de ce chapitre on utilisera le terme \textit{fog computing} indistinctement pour représenter les défis de l'\textit{edge computing}, des \textit{cloudlets}, des \textit{grids pervasifs} aussi que pour tout autre réseau faiblement couplés caractérisé par l'hétérogénéité des ressources.
 
%À une moindre mesure, nous pouvons essayer d'utiliser des plates-formes existantes comme point de départ pour le développement d'un réseau \textit{fog computing}. Une plateforme prometteuse serait celle du projet Apache Storm \cite{ApacheStorm}, basée sur un réseau P2P et permettant la soumission de services (topologies) dédiées au traitement de flux de données (\textit{streams}). Toutefois, la plateforme Apache Storm n'a pas été conçue pour une utilisation dans un environnement hétérogène et donc a l'inconvénient de ne pas prendre en compte les caractéristiques des machines ni leur contexte d'exécution. En effet, le réseau P2P est utilisé seulement pour rendre plus simple l'interconnexion des n{\oe}uds, mais le placement des unités de calcul (appelés "bolts") n'est pas remis en cause après le déploiement de la topologie. De plus, c'est une plateforme et en pleine mutation (elle vient de subir une mise à jour majeure) et assez complexe car riche en fonctionnalités tiers (authentification, RPC, APIs indépendantes du langage de programmation), ce qui rend plus difficile l'appropriation et l'insertion de fonctionnalités expérimentales. 


\section{De CONFIIT à CloudFIT}

CloudFIT est une plateforme de calcul distribué que reprend et élargit le paradigme FIIT (\textit{Finite number of Independent and Irregular Tasks}) défini par Krajecki \cite{Kraj99}. Par définition, un problème FIIT peut être décomposé en un ensemble de tâches qui respectent les trois conditions suivantes :
\begin{enumerate}
	\item une tâche ne peut faire aucune hypothèse sur la résolution d'une autre ;
	\item le temps d'exécution d'une tâche n'est pas prévisible ;
	\item un algorithme unique est utilisé pour résoudre les tâches, seules les données en entrée changent. 
\end{enumerate}

Ce paradigme de computation permet la représentation de la plupart des problèmes de calcul parallèle qui ne requièrent pas une dépendance forte entre les tâches. Il faut noter que cette restriction peut être dépassée et donc supporter des applications plus complexes, grâce à l'utilisation d'une synchronisation, à petit ou gros grain :

\begin{description}
\item [Synchronisation à gros grain] Avec une synchronisation à gros grain, deux \textit{jobs} sont exécutés en séquence, ce qui permet la synchronisation à la fin de chaque exécution. Ce modèle correspond au modèle de programmation BSP (Bulk-Synchronous Parallel) \cite{Valiant90}, qui repose sur la succession de \textit{supersteps}. Un \textit{superstep} est défini comme une séquence d'opérations locales, suivies par une barrière globale de synchronisation, exactement ce que se produit à la fin de l'exécution d'un \textit{job} FIIT. Comme dans BSP, aucune assomption n'est faite sur l'ordre d'exécution des tâches, la seule contrainte est que les données nécessaires au prochain \textit{superstep} soient disponibles au moment de la barrière. La Figure \ref{fig:Superstep}  illustre l'exécution d'un \textit{superstep} BSP dans lequel les n{\oe}uds exécutent leurs tâches et préparent les données pour le prochain \textit{superstep} avant la barrière.

\item [Synchronisation à grain fin] La synchronisation à grain fin permet d'obtenir la dépendance entre les tâches, à l'instar des \textit{Directed Acyclic Graph} (DAG). Pour cela, il suffit de modifier l'ordonnanceur de tâches afin de prendre en compte l'état des tâches et une liste de dépendances : une tâche ne sera lancée que si les tâches dont elle dépend sont déjà terminées. Bien que ceci viole la première propriété du modèle FIIT (l'indépendance entre les tâches), son implémentation est simple et permet le déploiement d'autres types d'application.
\end{description}


\begin{figure}
	\centering
		%\vspace{-0.3cm}
		\includegraphics[width=0.5\linewidth]{img/BSP}
		%\vspace{-0.4cm}
		\caption{Un superstep dans le modèle BSP}\label{fig:Superstep}
\end{figure}

Une première implémentation du paradigme FIIT a vu le jour avec la plateforme CONFIIT (\textit{Computation Over Network for FIIT}) \cite{FKF03,Flauzac10}. CONFIIT a été développé en tant que \textit{middleware} pour le calcul distribué, en s'appuyant sur un anneau logique (\textit{overlay}) géré par le \textit{middleware} et sur des échanges XML-RPC entre les n{\oe}uds. À la suite de sa version initiale, CONFIIT a été fortement modifié entre 2004 et 2006, avec l'addition de différents modes de calcul (distribué, centralisé), isolation (\textit{sandboxing}), observateurs extérieurs, etc. Ce développement a été fait notamment dans le cadre d'un projet supporté par l'agence ANVAR dans le but de créer une \textit{startup} dans le domaine du calcul distribué.
CONFIIT a été utilisé comme plateforme de calcul pour plusieurs travaux, notamment lors de la résolution parallèle des instances L(2,23) et L(2,24) du problème de Langford \cite{JK04}.

Lors du démarrage du projet STIC-AmSud PER-MARE, nous avons voulu utiliser CONFIIT comme plateforme pour l'exécution d'applications \textit{MapReduce}, mais nous avons rencontré plusieurs difficultés qui n'ont pas permis l'utilisation de CONFIIT pour la suite du projet. En effet, nous avons trouvé une faille dans la conception de l'anneau logique qui empêchait l'utilisation de CONFIIT pour les applications de type \textit{big data} : l'anneau était utilisé autant pour le passage des messages de service que pour la diffusion des données associées aux tâches. La transmission de masses de données plus importantes que quelques kilo-octets (ce qui était le cas avec Langford) occasionnait la congestion de l'anneau logique et empêchait la synchronisation des n{\oe}uds, causant ainsi leur déconnexion.

Après plusieurs tentatives, nous avons pris la décision de développer une nouvelle plateforme, plus à jour et disposant de ressources capables de supporter aussi les applications de type \textit{big data}. Cette nouvelle implémentation, appelée CloudFIT, sera décrite dans les sections suivantes. 


\subsection{Spécification des besoins}

La décision d'implémenter une nouvelle plateforme capable de supporter le paradigme FIIT (et ses variantes) dans un univers d'applications allant du calcul combinatoire au \textit{big data} a été suivie d'une liste d'exigences visant la généricité et la maintenance de la plateforme :

\begin{description}
	\item [R1] CloudFIT doit être indépendant de l'\textit{overlay} P2P. Ce choix rend possible le test de différents \textit{overlays} P2P, afin de mieux s'adapter aux environnements et besoins des applications ;
	\item [R2] CloudFIT doit être modulaire afin de supporter la composition et l'ajout de nouveaux modules, grâce à des interfaces et services bien définis. De plus, ceci doit permettre à l'utilisateur de composer "sa" pile logicielle sans avoir à modifier le code source, par exemple, grâce à un fichier de configuration externe ;
	\item [R3] CloudFIT doit supporter le déploiement d'applications à la volée. Un utilisateur doit pouvoir soumettre ses propres classes applicatives à CloudFIT, qui les intégrera à la file d'exécution et les déploiera aux différents n{\oe}uds du réseau.
\end{description} 


L'exigence [R1] vient directement de l'expérience précédente avec CONFIIT, où une dépendance trop forte par rapport au \textit{middleware} P2P a rendu la correction des \textit{bugs} trop difficile.  Comme les environnements pervasifs présentent des grandes variations autant en termes de performance que de capacité, les couches les plus proches du réseau doivent pouvoir s'adapter à ces contraintes, comme par exemple l'impossibilité d'effectuer des diffusions, la présence de proxies et de passerelles NAT, voir même le support à des communications par mémoire partagée si l'environnement le supporte. Le respect à cet objectif a été très utile car l'\textit{overlay} P2P initialement retenu (FreePastry\footnote{\url{http://www.freepastry.org/}}) s'est plus tard révélé peu performant et on a pu facilement migrer vers un nouvel \textit{overlay}, TomP2P\footnote{\url{http://tomp2p.net}}. 

L'exigence [R2] est autant une prérogative visant l'évolution et la maintenance de la plateforme qu'une manière de rendre plus simple l'expérimentation avec CloudFIT. De plus, le fait de reposer sur des interfaces permet une moindre dépendance entre les modules, demandant peu ou aucune modification de code en cas de remplacement d'un composant. 

Finalement, l'exigence [R3] garantit la scalabilité de la solution. En effet, il serait inconcevable de devoir déployer l’application sur les n{\oe}uds de calcul avant de la lancer à l’aide de la plateforme, comme c’était le cas avec CONFIIT. En effet, CONFIIT exigeait que les binaires de l’application soient déjà présents sur les n{\oe}uds avant même l’exécution de la plateforme, ce qui n'est pas toujours évident à faire dans un réseau dynamique où des nouveaux n{\oe}uds peuvent rejoindre la plateforme à tout moment. À notre avis, c'est bien le rôle de la plateforme d'effectuer ce déploiement et d'assurer le lancement des applications selon des appels bien définis dans l'interface applicative. 

\subsection{Architecture}

L'architecture de CloudFIT a été conçue selon les objectifs cités précédemment. Afin de renforcer la modularité de la plateforme, nous l'avons conçue sous la forme d'une pile logicielle, inspirée des modèles réseau TCP/IP et OSI. Ainsi, nous avons défini quatre couches représentant les différentes fonctionnalités de la plateforme : \textbf{Network}, \textbf{Protocol}, \textbf{Service} et \textbf{Application}.

\begin{figure}
	\centering
		\includegraphics[width=0.65\linewidth]{img/CloudFITstack}
		\caption{Représentation simplifiée de la pile logicielle CloudFIT}\label{fig:cloudFitStack}
\end{figure}

Malgré son nom, la couche \textbf{Network} est responsable pour toute interaction avec les systèmes tiers sur lesquels CloudFIT s'appuie (\textit{overlay} P2P, système  d'exploitation, systèmes de stockage). Par exemple, la classe \texttt{Network Adapter} exécute les opérations élémentaires d'encapsulation et décapsulation des messages, grâce à des primitives conçues selon les capacités des \textit{overlays} P2P subjacents (\textit{send}, \textit{sendAll}, \textit{receive}, etc.). Le même principe s'applique à la classe \texttt{Storage Adapter}, où des primitives comme \textit{read}, \textit{write}, \textit{delete}, \textit{lookup} font l'interface avec les différentes solutions de stockage possibles (fichiers locaux, DHTs, bases de données, stockage sur le cloud). On y trouve finalement le \texttt{Context Collector}, déjà présenté dans le chapitre précédent en Section \ref{sec:gestionnairecontexte} et qui a été intégré à CloudFIT aussi.

La couche \textbf{Protocol} est responsable notamment par la gestion des messages et les ressources de calcul. Ainsi, le module \texttt{Core-ORB} (nommé ainsi car son rôle est comparable à celui d'un \textit{Object Request Broker}) stocke les messages reçus de la couche Network et délivre ces messages aux services adéquats de la couche supérieure. Grâce à un mécanisme \textit{publish-subscriber}, différents services peuvent s'enregistrer auprès le \texttt{Core-ORB}, obtenant ainsi un identifiant unique utilisé pour la réception des messages mais aussi pour des éventuelles communications entre les services dans le même n{\oe}ud. 

Le \texttt{Resource Manager}, de son côté, puise dans les informations extraites par le collecteur de contexte pour vérifier si les ressources présentes dans la machine sont compatibles avec les besoins des applications. Ces besoins sont exprimés en tant que propriétés (mémoire nécessaire, espace disque, etc.) renseignées par l'application lors de sa soumission. Le \texttt{Resource Manager} est aussi responsable pour la gestion du pool de \texttt{Workers}, qui sont alloués aux applications selon les demandes faites par les ordonnanceurs de tâches. 

La couche \textbf{Service}  contient les services nécessaires à l'exécution des applications distribuées. À cette couche appartient notamment la classe \texttt{Community}, une abstraction d'un groupe de machines qui gère le déploiement des applications et la gestion des événements liés aux n{\oe}uds (entrée, sortie, retransmission de messages, etc.). CloudFIT définit une communauté par défaut regroupant l'ensemble des n{\oe}uds sur lé réseau, mais des instances supplémentaires peuvent être lancés afin de créer des sous-réseaux répondant à des besoins spécifiques (cloisonnement, localisation, etc.). Chaque communauté est associée à un \texttt{Job Scheduler}, qui gère la file d'applications soumises (\textit{jobs}) et choisit lesquelles peuvent être lancées sur la machine, en croisant les contraintes des applications et les informations du \texttt{Resource Manager}.  Il faut remarquer que plusieurs communautés peuvent coexister sur un n{\oe}ud et dans le réseau, permettant ainsi la création de sous-ensembles de n{\oe}uds et le déploiement d'applications selon différents critères. 

 D'autres services de cette couche incluent des interfaces de soumission ou de visualisation des résultats. Ces services sont notamment utiles dans l'interaction avec des dispositifs IoT qui n'ont pas la possibilité d'exécuter une instance de CloudFIT, comme par exemple les micro-contrôleurs Arduino. Dans ce cas, il suffit d'offrir un accès à un n{\oe}ud CloudFIT grâce à une interface REST ou JSON, comme suggère la Figure \ref{fig:cloudFitStackIoT}. Ces interfaces peuvent être utilisées autant pour le simple stockage de données que pour le déclenchement d'applications.

\begin{figure}
	\centering
		\includegraphics[width=0.65\linewidth]{img/CloudFITstack-IoT}
		\caption{Exemple d'interface IoT pour l'interaction avec CloudFIT}\label{fig:cloudFitStackIoT}
\end{figure}


Finalement, la couche \textbf{Application} contient les éléments nécessaires à l'exécution de l'application fournie par l'utilisateur. Cette couche spécifie l'interface applicative qui doit être implémentée par l'application utilisateur afin d'être exécutée par CloudFIT. L'interface applicative est assez simple et intuitive, suivant les principes du paradigme FIIT. Ainsi, le développeur n'a besoin que d'écrire les méthodes suivantes :
\begin{description}
	\item [numberOfBlocks()] méthode qui retourne le nombre de tâches à lancer. Cette méthode est appelée pendant la configuration du \texttt{Task Scheduler} ;
	\item [executeBlock(taskID, required{[]}) ] méthode qui démarre l'exécution proprement dite de la tâche, c'est le point d'accroche pour les \texttt{Workers}. Le \textit{taskID} permet à la tâche de personnaliser son exécution, et l'élément \textit{required[taskID]} indique les éventuelles dépendances de cette tâche. Ce paramètre est aussi utilisé par le \texttt{Task Scheduler} pour gérer l'ordre d'exécution afin de respecter les dépendances ;
	\item [finalizeApplication()] méthode optionnelle qui est exécutée par le \texttt{Task Scheduler} une fois que l'ensemble de tâches est terminé. Cette méthode permet l'agrégation des résultats, à l'instar d'une phase \textit{Reduce} dans le paradigme \textit{MapReduce}.
\end{description}

On y trouve aussi la classe\texttt{ Task Scheduler}, un ordonnanceur associé à chaque \textit{job} et responsable par la gestion des tâches et l'interaction avec le \texttt{Resource Manager} afin d'obtenir les \texttt{Workers} nécessaires pour l'exécution de ces tâches. La Figure \ref{Figure:applayer} présente de manière simplifiée l'interaction entre le \texttt{Task Scheduler}, l'application et les autres éléments de la couche Service: à la réception d'une nouvelle soumission (\textit{job}), celle-ci est confiée au \texttt{Job Scheduler} et puis au \texttt{Task Scheduler}, qui négocie l'obtention des \texttt{Workers}.   

\begin{figure}
	\centering
		\includegraphics[width=0.65\linewidth]{img/CloudFITstack-app}
		\caption{Diagramme simplifié de l'interaction entre les éléments lors du lancement d'un \textit{job} et de ses tâches}\label{Figure:applayer}
\end{figure}

Il faut noter que la classe \texttt{Task Scheduler} est extensible et personnalisable. Par défaut CloudFIT fournit un ordonnanceur simple, cependant celui-ci peut être remplacé par des ordonnanceurs plus élaborés ou particulièrement adaptés aux besoins des applications. L'ordonnanceur par défaut fait juste une redistribution aléatoire des tâches, une technique simple qui réduit le risque de travail en double entre les n{\oe}uds. Parmi les exemples d'ordonnanceurs plus élaborés, on peut citer ceux qui prennent en charge les dépendances entre les tâches (dans le cas d'une application DAG) ou qui utilisent des éléments de contexte, comme par exemple la localisation d'un n{\oe}ud, pour minimiser le temps d'accès aux données. 




\subsection{Communication\label{subsec:commCloudFIT}}

La section précédente illustrait la structuration et l'interaction des modules à l'intérieur d'une instance de CloudFIT. Cependant, une plateforme de calcul distribué se doit de garantir les échanges entre les différents n{\oe}uds sur le réseau. Dans le cas de CloudFIT, le choix d'utiliser un \textit{overlay} P2P tiers simplifie les opérations de découverte de pairs, la gestion du réseau (entrées, sorties), routage des messages, etc. Nous pouvons ainsi nous concentrer sur la communication intrinsèque à la plateforme, comme par exemple le déploiement des applications, le suivi de la progression de l'exécution et la distribution/récupération des résultats. 

Tout démarre par la soumission d'un \textit{job}, effectué directement par un n{\oe}ud déjà connecté au réseau ou grâce à une interface de soumission. Cette soumission contient le code applicatif, le nom de la \texttt{Community} cible, ainsi qu'une liste de propriétés nécessaires à la bonne exécution du \textit{job}. Un message contenant les paramètres et propriétés de la soumission est diffusé à travers le réseau, grâce aux mécanismes de communication de l'\textit{overlay} P2P.

Comme spécifié par l'exigence [R3], nous devons garantir qu'une application sera déployée par la plateforme elle-même, car il serait très contraignant pour l'utilisateur de devoir placer lui-même l'application sur chaque n{\oe}ud. Afin de répondre à ce besoin, nous avons choisi d'utiliser le stockage DHT, un service habituellement intégré aux différents \textit{overlays} P2P. En effet, le DHT offre à tous les n{\oe}uds de l'\textit{overlay} un accès réseau à des objets et des fichiers, du moment où ces n{\oe}uds connaissent la clé de ces ressources. Ainsi, la soumission d'un \textit{job} comprend l'enregistrement d'un fichier \textit{jar} contenant le code applicatif et la clé DHT de cette ressource. Au moment du lancement du \textit{job}, le \texttt{Job Scheduler} récupère ce fichier et extrait ses classes, qui seront chargées grâce à un \textit{classloader}. 

Le stockage DHT peut également être utilisé pour la mise à disposition de données d'entrée pour les applications \textit{big data}, dans lesquelles un important jeu de données doit être mis à disposition des applications. Ceci n'est pas obligatoire, vu que les applications ont aussi la possibilité d'obtenir les données via des ressources extérieurs (URLs, stockage cloud, bases de données).

Lorsqu'un \textit{job} démarre sur une machine, son statut passe de \textit{NEW} à \textit{STARTED}. À ce moment, le \texttt{Task Scheduler} associé à ce \textit{job} est démarré, et les tâches peuvent être lancées. Celles-ci ont 5 états possibles : \textit{NEW}, \textit{STARTED}, \textit{STARTED\_DISTANT}, \textit{COMPLETED} et \textit{DISTANT}, comme illustré par le cycle de vie présenté en Figure \ref{fig:etatsTasks}.

\begin{figure}
	\centering
	\includegraphics[width=0.65\linewidth]{img/lifecycle}
	\caption{Cycle de vie des tâches dans CloudFIT}\label{fig:etatsTasks}
\end{figure}

Lorsqu'une tâche est lancée, un message est envoyé aux n{\oe}uds de la \texttt{Community} indiquant le ID du \textit{job} et de la tâche. Ceci permet aux \texttt{Task Scheduler} des autres n{\oe}uds de savoir si cette tâche est traitée par une autre machine et ainsi de réduire le travail en double : ces tâches "distantes" sont marquées comme \textit{STARTED\_DISTANT} et sont placées à la fin de la file d'exécution. Une tâche marquée ainsi ne sera exécutée que lorsque toutes les tâches \textit{NEW} auront été épuisées et, bien sûr, si aucun autre message n'est venu indiquer que la tâche aurait été complétée. En effet, le \texttt{Task Scheduler} envoie un deuxième message à la fin de l'exécution d'une tâche, indiquant le changement de son statut à \textit{COMPLETED} et aussi indiquant le résultat de son calcul (ou bien les coordonnées pour retrouver ce résultat, qu'il soit stocké dans la DHT ou dans une ressource externe).

Si un n{\oe}ud finit l'exécution de toutes ses tâches \textit{NEW}, il peut démarrer l'exécution de tâches spéculatives parmi celles marquées \textit{STARTED\_DISTANT}. Ce mécanisme garantit la terminaison de toutes les tâches (si le n{\oe}ud original est défaillant, par exemple) et permet même d'accélérer la terminaison du calcul si le n{\oe}ud original est trop lent.

En plus de mettre à jour les autres n{\oe}uds, ces échanges de messages ont aussi le rôle de mettre au courant un nouveau n{\oe}ud qui rejoint le réseau. En voyant passer des messages de type "\textit{task completed}", les n{\oe}uds peuvent demander à un voisin de les transmettre le message avec la description du \textit{job}. Son \texttt{TaskManager} va donc procéder à la récupération des tâches \textit{DISTANT} grâce à des requêtes spécifiques. Ce mécanisme permet ainsi de garantir l'intégration des n{\oe}uds dans un environnement volatile et d'assurer la pérennité des résultats. En effet, il suffit qu'une machine subsiste dans le réseau pour que les résultats restent accessibles.

À la fin de l'exécution de toutes les tâches, les \texttt{TaskManager} récupèrent l'ensemble des résultats locaux ou distants et le statut du \textit{job} devient \textit{COMPLETED}. Ce \textit{job} reste à la disposition de toute application ou n{\oe}ud qui souhaite récupérer ses résultats.


\section{Calcul Multi-échelle et le \textit{Fog Computing}\label{sec:multiechelle}}

Comme indiqué précédemment, la plupart des travaux sur le \textit{edge/fog computing} ont la tendance à faire une distinction entre l'utilisateur final (ou les périphériques finaux) et les dispositifs qui se trouvent à la frontière de l'Internet/\textit{cloud}. Dans de telles approches, les appareils IoT sont des simples clients des services déployés dans un voisinage proche, ce qui est d'une certaine manière contraire aux principes du \textit{fog computing}, où tous les dispositifs peuvent contribuer au calcul des tâches selon leurs propres capacités et les ressources disponibles. 

Cependant, les réseaux P2P les plus connus organisent les n{\oe}uds indistinctement de leur emplacement réel, ce qui empêche l'établissement de services de proximité à faible latence. Pour contourner ces inconvénients, nous considérons que le réseau P2P de CloudFIT doit être enrichi par l'utilisation du concept de calcul multi-échelle \cite{Rottenberg2012,Rottenberg2014}  associé à des techniques de \textit{clustering}. En effet, le regroupement des ressources sous la forme de \textit{clusters} est une manière efficace d'organiser les couches de calcul multi-échelle et ainsi de fournir une base de coordination pour le déploiement efficace des services.

Plusieurs approches de \textit{clustering} sont proposées dans la littérature \cite{Johnen2011} et utilisées, par exemple, pour  le routage des informations dans les réseaux de capteur sans fil. La plupart des algorithmes de \textit{clustering} utilisent des paramètres simples comme la densité du réseau environnant ou la distance relative entre les n{\oe}uds. Malheureusement, ces métriques ne sont pas suffisamment riches pour exprimer les besoins du calcul multi-échelle dans un réseau hétérogène. 

En effet, l'un de nos défis est de permettre le regroupement des n{\oe}uds selon différentes stratégies guidées par les besoins des applications. Par exemple, certaines applications ont besoin de co-localiser les données et les ressources de calcul à des endroits précis afin de rendre des services de proximité. Dans d'autres cas, des réseaux classés selon les capacités de calcul des n{oe}uds pourront être mis à disposition des applications nécessitant des ressources plus homogènes. Ainsi, afin de s'adapter à l'hétérogénéité des environnements pervasifs et l'IoT, les métriques de clustering doivent permettre l'utilisation d'informations de contexte telles que la localisation ou la distance relative entre les n{\oe}uds, les vitesses CPU, la quantité de mémoire et de stockage des appareils, la fiabilité et même le niveau d'autorisation/confiance des n{\oe}uds collaborateurs. Bien entendu, un n{\oe}ud doit pouvoir appartenir à plusieurs clusters, permettant à des données et des tâches de circuler entre les différentes couches multi-échelle, comme illustrée en Figure \ref{fig:antennes}. Cette organisation à plusieurs niveaux en fonction du contexte des ressources disponibles permettrait de mieux coordonner la communication entre ces ressources et d'ainsi mieux gérer la variabilité d'échelle de ces environnements. 


\begin{figure}[!ht]
	%\renewcommand{\figurename}{Figura}
	\centering
	\includegraphics[width=0.5\linewidth]{img/antennes2.pdf}
	\caption{Exemple de communautés interconnectées dans une plateforme multi-échelle}
	\label{fig:antennes}
\end{figure}


Dans le cas de CloudFIT, ce \textit{clustering} pourrait être mis en {\oe}uvre grâce aux \textit{communautés}. En effet, dans la version actuelle de CloudFIT on peut déjà lancer différentes instances de la classe \texttt{Community}, chacune dotée d'un identifiant propre. Les soumissions transmises à une communauté X ne seront transmises qu'aux n{\oe}uds ayant des instances avec le même identifiant X, et donc il serait possible de créer des sous-ensembles de n{\oe}uds adressés séparément et donc utilisés pour répartir/cloisonner les opérations. Si actuellement la création des instances des communautés se fait de manière statique lors du lancement d'un n{\oe}ud, il est tout à fait envisageable de permettre la création à la volée de communautés en utilisant des messages spécifiques, transmises par le biais de la communauté par défaut qui relie tous les n{\oe}uds.  

Un autre problème ouvert dans le développement de CloudFIT est celui du partage de ressources. L'implémentation actuelle ne fait pas distinction entre les communautés, avec les demandes d'accès aux \texttt{Workers} étant traitées par ordre d'arrivée. Dans le cas où multiples communautés seront créés pour répondre à des besoins spécifiques, il serait peut-être nécessaire de revoir le partage de ressources afin de mieux respecter les spécifications de chaque communauté. 

 

\section{Optimisations pour le \textit{big data}\label{sec:datalocality}}
%
Dans le cadre du traitement de données issus des dispositifs de l'IoT, un autre facteur à prendre en compte est celui de la performance liée à l'accès et à la gestion des données. En effet, la plupart des opérations impliquent la collecte, la transformation et l'analyse des données. En effet, les plates-formes telles que Apache Hadoop se sont illustrées par leur capacité d'optimiser l'accès aux données grâce au concept de la \textit{data locality} : les tâches sont lancées en priorité sur les n{\oe}uds qui détiennent une copie des données à traiter. Cette allocation est généralement faite de manière transparente par le gestionnaire de ressources de Hadoop (le \texttt{Resource Manager}), qui est très couplé au gestionnaire des données de HDFS (le \textit{NameNode}). En effet, cette allocation peut expliquer le remplissage graduel des ressources observés lors de nos expériences en Chapitre \ref{chap:hadoop} : si les données sont distribués entre les n{\oe}uds dans un ordre précis, l'allocation des tâches aura tendance à suivre cet ordre.

Dans le cas de CloudFIT, l'accès aux données devient une préoccupation essentielle car nous ne disposons pas d'un service de stockage spécialement intégré aux mécanismes d'ordonnancement des tâches. Si nous avons déjà eu des résultats encourageants par le passé \cite{Steffenel2015Roma} laissant envisager des performances similaires ou supérieures à celles d’Apache Hadoop (voir la Figure \ref{fig:Hadoop}), il est claire que cela peut encore être amélioré. À ce fin, nous avons identifié deux points clés à traiter, (\textit{i}) la surcharge due à la gestion des données sur un n{\oe}ud et (\textit{ii}) la prise en charge de la \textit{data locality}. 

\begin{figure}[!ht]
	%\renewcommand{\figurename}{Figura}
	\centering
	%\vspace{-0.3cm}
	\includegraphics[width=0.65\linewidth]{img/CloudFIT-mesures.pdf}
	%\vspace{-0.2cm}
	\caption{Comparaison des temps d'exécution de WordCount avec CloudFIT et Hadoop}
	\label{fig:Hadoop}
	%\vspace{-0.2cm}
\end{figure}

Le premier cas concerne notamment les situations où des dispositifs de faible capacité sont associés à des équipements plus puissantes lors d'un déploiement d'un environnement hétérogène (l'un de ces scénarios sera présenté plus bas, en Section \ref{subsubsec:cloudfit-heterogene}). En effet, nous avons observé des écarts de performance très préoccupants sur ces dispositifs, dus à une combinaison de la faible vitesse d'accès aux données et de la surcharge due à la gestion des systèmes de stockage DHT. Ainsi, par exemple, un Raspberry Pi est fortement pénalisé par la vitesse et la capacité de stockage de sa carte SD, malgré une capacité de calcul suffisante (notamment en utilisant tous ses c{\oe}urs de calcul). 

En tenant compte que d'autres dispositifs de faible capacité tendent à devenir populaires grâce à l'IoT, nous avons rajouté une option au démarrage de CloudFIT visant à limiter la surcharge due à la gestion du stockage DHT. Cette option, qui consiste à renseigner un espace de stockage zéro au moment du démarrage de la DHT, permet aux n{\oe}uds d'agir seulement en tant que clients distants de la DHT. Ces n{\oe}uds peuvent donc interroger le service de stockage DHT via le réseau mais ils ne sont plus obligés à gérer le stockage, réduisant la surcharge liée à la gestion de la DHT ainsi que leur besoin d'espace en disque (ce que peut être un atout quand la capacité de la carte SD n'est que de quelques gigaoctets).

Une toute autre approche est nécessaire pour répondre aux besoins du deuxième cas, la prise en charge de la localisation des données (\textit{data locality}). Tout d'abord, ceci est un problème plus général, qui affecte la plupart des architectures de stockage P2P. En effet, les API de stockage de type DHT sont conçues de manière à répartir les données sur le réseau et les répliquer lorsque cela est possible, notamment afin d'éviter la perte de données en cas de désabonnement (\textit{churn}). Un inconvénient de cette procédure est qu'on observe une perte d'information concernant la localisation des données \cite{Wu2005}, rendant difficile l'optimisation des transferts réseau. Nous avons donc développé deux mécanismes distincts visant à contourner cette limitation. 

La première approche que nous avons développée peut facilement être mise à l'{\oe}uvre si on un accès à la bibliothèque DHT. Cette stratégie consiste à instruire l'ordonnanceur de tâches (\textit{Task Scheduler}) à vérifier préalablement quelles tâches seraient favorisées par la présence des données dans son cache DHT local. Même si c'est une opération de bas niveau, la plupart des DHT P2P offrent la possibilité d'effectuer un \textit{lookup} pour savoir si la ressource requise se trouve déjà dans le cache local ou s'il faut la chercher sur le réseau. En donnant la priorité aux tâches qui peuvent travailler avec des données locales, on peut espérer augmenter la performance globale de l'exécution.

Toutefois, il n'est pas toujours possible d'avoir des données en local dans un \textit{overlay} P2P. En effet, dans une DHT les n{\oe}uds responsables par le stockage et l'indexation des ressources sont définis par la clé de hachage de la ressource. Si la fonction de hachage n'est pas spécifiquement conçue pour la \textit{data locality}, elle aura tendance à répartir équitablement les clés, provocant l'éparpillement des données.  Ceci nous amène à réfléchir sur une stratégie pour renforcer la proximité des données, grâce à un calcul personnalisé de la clé de localisation des ressources. 

%
%\begin{figure}[!ht]
%	%\renewcommand{\figurename}{Figura}
%	\centering
%	%\vspace{-0.3cm}
%	\includegraphics[width=0.4\linewidth]{img/AnneauPastry.pdf}
%	%\vspace{-0.2cm}
%	\caption{Exemple de routage d'un message dans l'\textit{overlay} Pastry \cite{Castro2002}}
%	\label{fig:pastry}
%	%\vspace{-0.2cm}
%\end{figure}
%

Cette technique a été élaborée sur la base des spécificités de la DHT de TomP2P, et donc ne peut pas être facilement généralisée. Contrairement à la plupart des systèmes de P2P qui ont seulement une clé de hachage, TomP2P identifie les ressources par quatre clés différentes $\{k_l,k_d,k_c,k_v\}$, selon la hiérarchie suivante : 
\begin{itemize}
	\item \textit{$k_l$} - clé de localisation, utilisée pour la localisation d'une ressource dans la DHT ;
	\item \textit{$k_d$} - clé de domaine, fonctionne comme une clé d'authentification, permet la séparation des données ;
	\item \textit{$k_c$} - clé de contenu, permet d'identifier une ressource. Par défaut celle-ci est identique à la clé de localisation ;
	\item \textit{$k_v$} - clé de version, permet la gestion de versions multiples d'une ressource.
\end{itemize} 

La clé de localisation est celle qui s'approche le plus des clés DHT traditionnelles, ayant par fonction l'association d'une ressource (copie primaire ou index) au n{\oe}ud avec l'ID le plus proche. Sans aucune instruction supplémentaire, la clé de localisation et la clé de contenu sont identiques, mais peuvent être différenciées, par exemple, afin résoudre les cas de collision de clés (deux ressources générant la même clé de localisation).

La clé de domaine est liée à un mécanisme d'authentification simple de TomP2P. Son but est de renforcer le cloisonnement de données des différents clients (cette authentification peut être renforcée par l'utilisation de la cryptographie afin de garantir une véritable confidentialité). Dans le cas de CloudFIT, la clé de domaine est utilisée comme un \textit{namespace} pour la séparation des données de différents communautés ou \textit{jobs} de calcul. 

Finalement, la clé de version permet la coexistence de différentes versions d'une ressource, ce qui permet une meilleure gestion des données "mutables" avec, par exemple, l'accès à l'historique des modifications ou l'écriture en parallèle d'une ressource par plusieurs n{\oe}uds. Cette clé de version est utilisée dans les nouvelles versions de l'application \textit{MapReduce} développée sur CloudFIT.

Ainsi, afin de renforcer la \textit{data locality}, nous avons travaillé sur le découplage entre la clé de localisation et la clé de contenu grâce à une double fonction de hachage. Dans un premier moment, la clé de contenu est obtenue avec une méthode de hachage classique. Ensuite, la clé de localisation est calculée en faisant une association limitée aux ID des n{\oe}uds d'une communauté. La Figure \ref{fig:hash} montre l'exemple de cette cartographie en calculant la clé de localisation d'une ressource $r_3$ par rapport à une communauté $Comm_1$.

\begin{figure}[!ht]
	%\renewcommand{\figurename}{Figura}
	\centering
	%\vspace{-0.3cm}
	\includegraphics[width=0.5\linewidth]{img/hashing.pdf}
	%\vspace{-0.2cm}
	\caption{Cartographie des ressources renforçant la \textit{data-locality}}
	\label{fig:hash}
	%\vspace{-0.2cm}
\end{figure}

Comme la clé de localisation se trouvera parmi les n{\oe}uds de la communauté, on augmente la probabilité de trouver la copie primaire dans les n{\oe}uds concernés. De plus, cette stratégie n'empêche pas la réplication des données sur d'autres n{\oe}uds, garantissant la persistance des données en cas de défaillance. Cette approche est aussi tolérante aux variations du nombre de membres de la communauté : en cas de disparition d'un n{\oe}ud, c'est une réplique qui prend le relais ; en cas d'un nouveau membre, celui-ci sera intégré à la fonction de hachage normalement.   

Tout comme la création à la volée des communautés dans CloudFIT, la stratégie présentée ici n'a pas encore été implémentée. Elle fait donc partie des développements que je compte poursuivre dans les prochains mois, afin de mieux équiper CloudFIT et poursuivre mes recherches autour du \textit{fog computing}.

\section{Exemples d'Utilisation de CloudFIT}

En tant que plateforme expérimentale pour le calcul distribué et le \textit{fog computing}, CloudFIT est en constante évolution. Cela n'empêche pas son utilisation comme plateforme de calcul dans certains de nos projets, notamment ceux dont l'objectif est d'utiliser des réseaux avec des éléments volatiles ou avec des ressources hétérogènes. Le premier exemple ci-dessous illustre une utilisation "recherche" pour le projet STIC-AmSud PER-MARE, dans le but d'évaluer le comportement de CloudFIT en tant que plateforme \textit{MapReduce} pour les environnements pervasifs. Le deuxième exemple démontre une utilisation "production", où CloudFIT a été utilisé pour exécuter un workflow destiné aux sciences de l'atmosphère. Ce dernier travail a servi de base  pour la proposition du projet de collaboration CAPES-Cofecub MESO. 


\subsection{L'application WordCount}

Le projet STIC-AmSud PER-MARE (\textit{Adaptive Deployment of MapReduce-based Applications over Pervasive and Desktop Grid Infrastructures}) avait pour but le développement de stratégies pour le déploiement d'applications \textit{MapReduce} sur des environnements pervasifs, comme nous l'avons expliqué en Chapitre \ref{chap:hadoop}. Si l'un des volets du projet a été celui d'adapter Apache Hadoop, l'autre volet consistait à utiliser CloudFIT en tant que plateforme de calcul distribuée. Si dans l'article présenté à CLIoT 2015 \cite{Steffenel15Taormina} nous nous sommes concentrés sur la performance de CloudFIT (voir aussi la Figure \ref{fig:Hadoop}), le travail présenté à CN4IoT \cite{Steffenel2015Roma} analysait l'exécution de CloudFIT par rapport à la volatilité et l'hétérogénéité des ressources.

\subsubsection*{Impact de la volatilité}

Afin d'évaluer l'impact de la volatilité des n{\oe}uds dans CloudFIT, nous avons effectué le déploiement d'une application \textit{MapReduce} simple (\texttt{WordCount}) sur un corpus de textes faisant 1 GB de données et réparti en blocs uniformes de 64 MB. Cette répartition vise à reproduire le comportement de Hadoop, qui lui aussi traite les données par blocs de 64 MB.  Aussi afin de rendre la visualisation des expériences plus simple, les n{\oe}uds sont identiques et ont été explicitement limités à une seule exécution simultanée (un seul \texttt{Worker}). 

Dans un premier moment et afin d'avoir un barème de comparaison, la Figure \ref{fig:regular} présente le diagramme de Gantt pour une exécution sans incidents. 
Nous pouvons apercevoir les effets du mécanisme d’ordonnancement distribué utilisé par défaut sur CloudFIT (cf. \ref{subsec:commCloudFIT}).
 En effet, lorsque la liste de tâches est reçue par le Task Scheduler, celle-ci est réordonnée de manière aléatoire, ce qui s'observe grâce aux tonalités des tâches (ces tonalités ont été attribuées avant le réordonnancement, en utilisant une échelle partant du blanc pour la tâche 0 puis en la noircissant jusqu'à la tâche \textit{n}). L'ordonnanceur choisit ainsi la première tâche disponible marquée "\textit{NEW}" dans sa liste et avertit les autres n{\oe}uds que cette tâche est en exécution. De manière similaire, à la fin de son exécution son statut est diffusé pour annoncer la fin de la tâche. Si toutes les tâches "\textit{NEW}" ont déjà été prises, un n{\oe}ud peut lancer des tâches spéculatives parmi celles marquées "\textit{STARTED\_DISTANT}". 

Plus spécifiquement, nous pouvons observer le déploiement de plusieurs tâches \textit{map} (lesquelles ont des temps d'exécution variable selon le nombre de mots dans les documents), puis d'une grande tâche \textit{reduce} qui s'exécute à la fin. Bien que l'exemple \texttt{WordCount} ne contienne qu'une tâche \textit{reduce}, celle-ci se trouve exécutée par tous les n{\oe}uds car si le premier n{\oe}ud a marqué la tâche comme "\textit{STARTED}" et prévient les autres, ceux-ci n'ont rien de plus dans leur file d'exécution et lancent le \textit{reduce} en tant que tâche spéculative. Mis à part l'utilisation des ressources de calcul, ceci n'a aucun impact sur le résultat final de l'application car les n{\oe}uds vérifient la présence d'un fichier de sortie avant de l'écrire sur la DHT, empêchant tout écrasement ou corruption. 

\begin{figure}
	\centering
		\includegraphics[width=1\linewidth]{img/regular2}
		\caption{Exécution de WordCount sur un \textit{cluster} uniforme (1 GB de données en blocs de 64MB)}\label{fig:regular}
\end{figure}




Grâce à ces échanges, il est aussi possible de compléter les tâches initiées par les n{\oe}uds en défaillance ou mettre au courant un n{\oe}ud qui vient de rejoindre une communauté CloudFIT. La Figure \ref{fig:1out} représente ainsi une situation où le n{\oe}ud numéro 1 tombe en panne, avec la subséquente reprise des tâches par les autres n{\oe}uds. La Figure \ref{fig:reprise} va au-delà de cette situation en rajoutant un nouveau n{\oe}ud (numéro 5), qui récupère l'état actuel des tâches et peut ainsi contribuer avec l'effort de calcul.
\begin{figure}
	\centering
		\includegraphics[width=1\linewidth]{img/1out2}
		\caption{Exécution de WordCount lorsqu'un n{\oe}ud disparaît (1 GB de données en blocs de 64MB)}\label{fig:1out}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[width=1\linewidth]{img/reprise2}
		\caption{Exécution de Wordcount lorsqu'un n{\oe}ud rejoint la communauté après la défaillance d'un autre n{\oe}ud (1 GB de données en blocs de 64MB)}\label{fig:reprise}
\end{figure}


\subsubsection*{Impact de l'hétérogénéité\label{subsubsec:cloudfit-heterogene}}

Les expériences de la section précédente ont donné un aperçu de la distribution des tâches de CloudFIT en cas de volatilité des n{\oe}uds. Maintenant, nous souhaitons observer ce comportement dans un environnement hétérogène, où des facteurs tels que la puissance de calcul peuvent déséquilibrer la répartition des tâches entre les n{\oe}uds. Pour cela, nous avons interconnecté quatre n{\oe}uds avec des spécifications assez différentes (cf. le Tableau \ref{Table:laptops}). Comme dans l'expérience précédente, nous limitons le nombre de c{\oe}urs (\texttt{Workers}) sur les machines pour rendre la visualisation plus simple.

\begin{table}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|c|}
			\hline
			Type de N{\oe}ud & Processeur & GHz &  Mémoire & OS\\
			\hline
			\hline
			MacBook Air & Intel Core i7-4650U & 1.7   & 8 GB & MacOS 10.10.5 \\
			Lenovo U110 & Intel Core2 Duo L7500 & 1.6   & 4 GB & Ubuntu Linux 15.4 \\
			Raspberry Pi 2 & ARM Cortex-A7 & 0.9  & 1 GB & Raspbian Linux Wheezy\\
			VM Virtualbox & Intel Core i7* & 2.2*  &  1 GB & Debian Linux 8.2 \\
			\hline
			\multicolumn{5}{l}{* ces valeurs sont celles vues par la machine virtuelle}
		\end{tabular}
	\end{center}
	\caption{\label{Table:laptops}Spécification des n{\oe}uds du \textit{cluster} hétérogène}
\end{table} 

Nous avons aussi modifié les paramètres de l'expérience afin d'exécuter le WordCount sur 512MB de données divisées en petits blocs de 2MB seulement ; nous pensons que cette configuration est plus proche de celle rencontrée lors de la transmission de données par les dispositifs IoT. La multiplication de tâches avec un coût individuel plus réduit rend aussi possible la participation des n{\oe}uds avec moins de puissance de calcul.  La Figure \ref{fig:hetero} affiche le diagramme de Gantt pour une exécution de ce scénario, dans lequel nous pouvons trouver côte à côte deux ordinateurs portables, une machine virtuelle exécutant sur un ordinateur de bureau et un Raspberry Pi 2. 

\begin{figure}
	\centering
		\includegraphics[width=1\linewidth]{img/hetero2}
		\caption{Exécution de Wordcount dans un \textit{cluster} hétérogène (512MB en blocs de 2MB)}\label{fig:hetero}
\end{figure}

Alors que la répartition des tâches entre les notebooks et la machine virtuelle ne présentent pas une différence significative, le Raspberry Pi, sans surprise, n'arrive pas à exécuter les tâches aussi vite que les autres n{\oe}uds (voir la longueur des tâches dans la première partie de l'exécution). De plus, ce n{\oe}ud est tellement surchargé qu'il perd plusieurs messages de mise à jour et ne détecte pas la fin de la phase \textit{map} et vers l'instant 1500s il essaye vainement d'exécuter toutes les tâches qu'il estime incomplètes, juste pour se rendre compte que leurs résultats sont déjà dans la DHT et donc avorter leur exécution. 

Au lieu de freiner notre intérêt par les dispositifs de faible puissance, ces résultats nous incitent à vouloir comprendre les raisons de ces problèmes. En effet, les dispositifs de faible puissance tels que les Raspberry Pi n'ont pas seulement des processeurs moins rapides mais ont également des limitations sur la taille et la vitesse d'accès à la mémoire et au stockage (quelques centaines de MB de RAM, des mémoires SD à la place des disques durs, etc.). Dans ces dispositifs, les tâches de gestion de l'\textit{overlay} P2P et de la DHT (par exemple, la réplication des données) peuvent occuper une partie importante de leurs ressources et finir par interférer avec le traitement des messages échangé via l'\textit{overlay}.  Ces résultats ont motivé la mise en place d'une stratégie de collecte de contexte pour un meilleur ordonnancement et aussi de méthodes d'optimisation du stockage que nous avons détaillé dans la section précédente. 

\subsection{Détection d'Événements Secondaires de la Couche d'Ozone\label{subsec:ozone}}

La découverte du trou d'Ozone de l'Antarctique \cite{Farman1985} a galvanisé l'intérêt de la communauté scientifique et, depuis ce moment, plusieurs études ont été menées dans le but de surveiller la variation de la densité de la couche d'Ozone sur les régions polaires \cite{Solomon1999}\cite{Salby2012}. La réduction de la couche d'Ozone peut aussi déclencher plusieurs événements sur des zones situées à des latitudes moyennes, soit à cause du mouvement de la bordure du vortex polaire sur ces régions  \cite{Kirchhoff1997}\cite{Marchand2005} ou bien à cause du transit de masses d'air pauvres en Ozone détachées du vortex polaire. Ce dernier cas est appelé "événements dus à l'influence du trou d'ozone Antarctique", ou plus simplement des Événements Secondaires de l'Ozone" (\textit{Ozone Secondary Events}  - OSE). 

Causés par la circulation de l'atmosphère, ces masses d'air continuent à se déplacer pendant 7 à 20 jours après leur séparation du vortex polaire et peuvent atteindre des latitudes plus élevées, occasionnant une réduction temporaire de la colonne totale d'Ozone (\textit{Total Column Ozone} - TCO) sur des zones qui sont souvent habitées \cite{Prather1990}\cite{Waugh1994}\cite{Manney1994}. Comme résultat, des niveaux élevés de radiation ultraviolet nocive (UVB et UVC) atteignent la surface \cite{Casiccia2008}, à un tel point qu'une réduction de 1\% de la colonne totale d'Ozone peut occasionner une augmentation de 1.2\% de la radiation UV mesurée sur le sud du Brésil \cite{Guarnieri2004}. Ces événements secondaires de l'Ozone sont régulièrement observés sur des zones peuplés en moyenne latitude, comme par exemple en Amérique du Sud \cite{Kirschhoff1996}\cite{Pinheiro2011}, en Afrique du Sud \cite{Semane2006}\cite{Sivakumar2007}, à la Nouvelle Zélande \cite{Brinksma1998} et aussi sur l'Île de la Réunion \cite{toihir2015}. 

%\begin{figure}
%	\centering
%	\includegraphics[width=0.75\linewidth]{img/22_10_13-c}
%	\vspace{-0.2cm}
%	\caption{OMI satellite image for 18 October 2013 (a) and the associated wind currents for (b) 19 and (c) 22 October 2013 at 620K}
%	\label{fig:event2013}
%	\vspace{-0.3cm}
%\end{figure}

Malgré une forte liaison avec la dynamique de la stratosphère, le nombre d'études visant la modélisation de la circulation dynamique de la couche d'Ozone sont encore très rares \cite{Marchand2005}. En effet, la plupart des modèles climatiques se limitent aux couches inférieures de l'atmosphère, notamment celles liées à aux prévisions météorologiques, et n'explorent pas les interactions avec les couches supérieures comme celle où se trouve la couche d'Ozone. Plus récemment, un modèle obtenu par Vaz Peres \cite{Peres2013} a permis une certaine compréhension de ces phénomènes. En se concentrant sur les données d'épisodes OSE déjà identifiés dans le passé, le modèle de Vaz Peres a permis la reproduction des événements observés. En partant de cette étude, notre but était d'utiliser des techniques du \textit{big data} et du \textit{data mining} afin de ramasser plus de données et possiblement d'en extraire des modèles plus précis, permettant la prévision de l'occurrence de ces événements.

L'utilisation de techniques du \textit{big data} est essentiel car les données concernant la couche d'Ozone s'accumulent d'année en année. Par exemple, l'équipement TOMS/OMI placé dans les satellites de la NASA produit plus d'1GB de données brutes par an. Juste les observations des satellites TOMS/OMI remontent à 1978 (ce qui fait presque 40 GB en ce moment), et à cela on peut rajouter d'autres sources de données satellites telles que les satellites de l'ESA mais aussi des observations effectuées au sol par des appareils de type Dobson ou Brewer. 

\subsubsection*{Identification des événements secondaires de l'Ozone avec CloudFIT\label{sec:development}}

Si dans un premier temps l'usage d'une plateforme type \textit{cluster} ou \textit{cloud} pourrait être envisagée, notre attention s'est portée rapidement sur CloudFIT car celui-ci a l'avantage d'exploiter les ressources de calcul disponibles, sans obliger l'installation ou la maintenance d'un parc informatique dédié. En autre, le traitement des données et la détection des OSE varie selon la zone géographique couverte et selon le type d'analyse effectuée : la détection d'événements passés utilisée pour améliorer les modèles est assez simple, alors qu'une analyse plus poussée visant l'étude des corrélations entre les événements et les courants atmosphériques peut s'avérer bien plus demandeuse de ressources. L'utilisation de CloudFIT permettrait ainsi la création d'une plateforme de calcul élastique.

Dans le cas précis de la détection des OSE, nous avons identifié quatre activités principales qui peuvent être transposées sur CloudFIT. Ces activités sont les suivantes : 
\begin{enumerate}
	\item \textbf{Prétraitement des données} - transformation des données brutes OMI au format JSON, plus adapté à nos besoins ;
	\item \textbf{Filtrage et agrégation} - sélection des données concernant une zone géographique et une période donnée, puis des opérations d'agrégation si nécessaire ;
	\item \textbf{Extraction des paramètres} - extraction des moyennes et écarts types pour une région et une période donnée ;
	\item \textbf{Détection des événements} - identification des valeurs anormales d'Ozone, génération d'alertes.
\end{enumerate}

Le prétraitement des données est nécessaire car les données brutes fournis par l'équipement TOMS/OMI sont dans un format spécifique qui requiert un \textit{parser} propre (la NASA fournit un code FORTRAN pour cela). Dans notre cas, ces données sont transposés sur une structure JSON qui permet la recherche des entrées à partir de leurs coordonnées. Le filtrage permet de limiter la recherche sur une zone géographique et/ou sur une période d'étude, alors que l'agrégation permet l'obtention de données à une granularité différente de celle d'origine (utile notamment pour la corrélation avec d'autres types de données). En effet, la plupart des données TOMS/OMI ont une résolution d'1 dégrée, alors que d'autres sources de données ont parfois des cartographies plus détaillées (par exemple, avec 0.25 dégrée d'arc entre chaque mesure). Cette procédure sera détaillée dans la section suivante.

L'extraction des paramètres est la prochaine étape car la détection d'un OSE est liée à l'observation d'une chute anormale de la concentration de l'Ozone. Pour cela, il faut extraire des paramètres historiques tels que la moyenne et la variation (écart-type), et cela pour chaque coordonnée analysée. Cette procédure est  détaillée dans les sections suivantes. Finalement, la détection se fait en comparant la mesure d'un instant précis avec la série temporelle des journées précédentes. Si les valeurs sont inférieures à la variation normale de la période, alors on peut déclencher une procédure d'alerte, signalant aux autorités sanitaires un risque lié à la radiation UV qui menacerait la population.

Les trois premières activités sont des exemples d'opérations ETL (\textit{Extract, Transform, Load}) typiques du \textit{big data}. La dernière activité peut être considérée comme un algorithme de prise de décision. Nous avons donc établi un workflow qui peut être transcrit comme un enchaînement de \textit{jobs} CloudFIT, comme illustré en Figure \ref{fig:blocs}. 

Afin de mieux répartir la charge entre les n{\oe}uds, nous avons aussi utilisé le concept de calcul multi-échelle pour répartir les quatre premiers \textit{jobs} (\textit{Preprocess}, \textit{Filtering}, \textit{Time-series} et \textit{Detection}). Comme expliqué en section \ref{sec:multiechelle}, nous pouvons organiser les n{\oe}uds en démarrant des instances différentes des communautés CloudFIT. Ainsi, une communauté C1 composée d'équipements entrée de gamme sera dédiée au prétraitement et au stockage des données des satellites et des spectre-photomètres Brewer ou Dobson installés au sol. 

Par la suite, les données peuvent donc être traitées pour la détection ou bien être utilisées pour des analyses plus poussées telles que la recherche de motifs récurrents ou la prévision d'événements futurs. Les activités telles que le filtrage et l'analyse des séries temporelles demandent des ressources de calcul plus importants, fournis par la communauté C2.
La Figure \ref{fig:blocs} inclut aussi d'autres communautés (C3 et C4) qui pourraient être déployées séparément afin d'effectuer les autres activités liées à la détection et à la prévision des OSE (ces étapes n'ont pas encore été implémentées). Il faut noter que cette organisation répond aussi aux principes du calcul multi-échelle et du \textit{fog computing}, l'un des objectifs de CloudFIT.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{img/4-process}
	\caption{Organisation des activités dans un réseau CloudFIT}\label{fig:blocs}
\end{figure}

\subsubsection*{Prétraitement des données}

Les mesures de la colonne totale d'ozone peuvent être obtenues par des équipements au sol mais aussi par le biais des satellites, qui ont l'avantage d'offrir une couverture globale. L'un de ces équipements, l'instrument TOMS/OMI, rend publique les données consolidées de la couverture du globe, une fois par jour. Dans le cas de la détection des événements secondaires de l'Ozone, nous avons besoin des données brutes obtenues par les satellites. Ces données sont présentées selon le format illustré en Figure \ref{fig:toms}(a), ce qui n'est pas vraiment adapté à l'utilisation directe pour nos calculs. Chaque fichier contient un entête avec des informations sur le fichier (date, les coordonnées du grillage, le pas), suivi des mesures pour chaque latitude (indiquée à la fin de la ligne), et cela pour toutes les longitudes couvertes. Chaque mesure est exprimée en unités Dobson (UD), représentées par un entier à 3 chiffres qui doit être séparé des mesures des autres longitudes. Par exemple, les coordonnées (-89.5,-179.5) de la Figure \ref{fig:toms}(a) ont la valeur 280, les coordonnées (-89.5,-178.5) ont aussi la valeur 280, et ainsi de suite.   

\begin{myverbbox}[\tiny]{\TOMS}
	Day:   1 Jan  1, 2013    OMI TO3    STD OZONE    GEN:13:003 Asc LECT: 01:44 pm 
	Longitudes:  360 bins centered on 179.5  W  to 179.5  E   (1.00 degree steps)
	Latitudes :  180 bins centered on  89.5  S  to  89.5  N   (1.00 degree steps)
	280280280280280280280280280280280280280280280280280280280279279279279279279
	279279279279279279279279279279279279279279279279279279279279279279279279279
	279279279279279279279279279279279279279279279279279279279279279279279279279
	279279279279279279279279279279279279279279279279279279280279280280280280280
	280280280280280280280280280280280280280280280280280280280280280280280280280
	280280280280280280280280280280280280280281281281281281281281281281281281281
	(...)
	282282282282282282282282282282   lat =  -89.5
	(...)   lat =  -88.5
	(...)   lat =  -87.5
	(...)
\end{myverbbox}

\begin{myverbbox}[\tiny]{\JSON}
	{
		"date":"20130101",
		"step":"1.0",
		"latitudes":{
			"-89.5":["-179.5":"280","-178.5":"280",(...)],
			"-88.5":["-179.5":"272","-178.5":"272",(...)],
			(...)
		}
	}
\end{myverbbox}

\begin{figure}
	\centering
	\begin{tabular}{cc}
		\imagetop{\TOMS}&\imagetop{\JSON}\\
		{\small (a)}&{\small (b)}
	\end{tabular}
	%\vspace{-0.2cm}
	\caption{Fichier brute OMI Ozone (a) et sa représentation JSON (b)}\label{fig:toms}
	%\vspace{-0.3cm}
	
\end{figure}

Comme ce format est difficile à comprendre et à traiter (il faut parcourir l'ensemble des entrées d'une latitude pour obtenir une mesure à une longitude donnée), nous avons décidé de prétraiter ces fichiers et les stocker sur la DHT en tant qu’objets JSON, selon le \textit{template} présenté en Figure \ref{fig:toms}(b). JSON est un format structuré de données bien connu, qui peut être facilement requêté, importé sur des bases de données ou bien stocké directement dans des bases NoSQL orientées  documents. Le prétraitement est facilement parallélisable car chaque journée peut être traitée indépendamment des autres. De plus, le stockage sur une DHT permet la réutilisation de données déjà traitées et l'ajout de nouvelles entrées à chaque jour. 

\subsubsection*{Analyse des séries temporelles et la détection des OSE\label{sec:timeseries}}

Comme indiqué précédemment, les OSE sont caractérisés par la réduction anormale de la colonne totale d'Ozone, alors que cela n'est pas directement lié à l'expansion du vortex polaire. Le détection des OSE est faite en comparant la mesure d'une journée et les moyennes historiques pour cette région. Cependant, le choix de ce qu'on considère la "période historique" a un impact important sur la perception des événements. Pour commencer, on ne peut pas utiliser la moyenne annuelle car la concentration d'Ozone varie de façon saisonnière (dans l'hémisphère sud elle est plus basse à l'Automne et plus haute au Printemps). 

L'approche utilisé par Perez \textit{et al. }\cite{Peres2013} considérait la moyenne historique mensuelle, i.e., la moyenne historique de chaque mois des années enregistrées. Si cela permet déjà la détection de certains OSE, cette méthode n'est pas suffisamment précise car la concentration naturelle varie d'année en année et aussi parce que la variation entre le début et la fin d'un mois est très importante dans les mois de transition comme juillet ou novembre. L'utilisation d'une moyenne standardisée aurait comme conséquence un nombre important de faux-positifs et faux-négatifs. Vu que nous disposons de ressources de calcul, nous avons décidé d'utiliser une approche par fenêtres glissantes, où par exemple chaque mesure est comparée à la moyenne des 15 jours précédents. Cette solution (l'utilisation de \textit{time series}) est plus proche de la réalité et prend en compte la variation naturelle pour la période étudiée.

Comme pour le prétraitement des fichiers d'entrée, cette activité peut être exécuté en parallèle car chaque coordonnée (X, Y) a son propre ensemble de données. De même, le calcul de la moyenne et de l'écart type est indépendant pour chaque jour choisi, vu que la fenêtre glissante couvre des dates différentes. Ainsi, dans l'implémentation CloudFIT, les tâches de calcul sont définies en fonction du nombre de coordonnées. Chaque tâche lit les valeurs pour les 15 jours précédents et calcule la moyenne et l'écart type. Par exemple, si nous considérons la zone couverte par les coordonnées \{(-70.5, -84.5), (-20.5, -29.5)\} (les mêmes utilisées en Figure \ref{fig:progression}) avec un pas d'1 dégrée pour le grillage, nous avons 50x55 points à analyser (2750 tâches). 

Une fois obtenus la moyenne et l'écart type pour chaque coordonnée et pour chaque jour cible, la détection des OSE peut être effectuée.  Pour cela, nous utilisons la formule simple présentée en Équation \ref{eq:equation}. Cette formule considère qu'un OSE existe si la valeur mesurée est inférieure à un seuil déterminé en fonction de la moyenne des 15 derniers jours et de la latitude (dans le cas du sud du Brésil on considère ce seuil à $1.5 \times$ l'écart type). Des paramètres additionnels tels que la vorticité potentielle pourraient être rajoutés afin d'augmenter la précision des détections.

\begin{equation}
Detection(v)=\left\{ \begin{array}{c}
\begin{array}{lll}
\textbf{True} & &if \:\: v \:< (average - 1.5\times stdev)\\
\textbf{False} & &otherwise\end{array}\end{array}\right.
\label{eq:equation}
\end{equation}



\subsubsection*{Résultats préliminaires}

Afin de valider l'implémentation, nous avons comparé les données de Peres \textit{et al.} \cite{Peres2013} avec les résultats obtenus à partir du workflow CloudFIT. Comme attendu, notre implémentation permet d'observer la progression du front OSE entre le 18 et le 22 octobre 2013 (Figure \ref{fig:progression}). On observe que le mécanisme de détection mis en place permet de se concentrer uniquement sur les zones ayant subi une variation importante de la colonne d'Ozone et pas sur celles qui habituellement ont une concentration réduite (comme par exemple le pôle ou les régions australes de l'Argentine et du Chili). 

\begin{figure}
	\centering
	\includegraphics[width=0.19\linewidth]{img/20131018-b}~\includegraphics[width=0.19\linewidth]{img/20131019-b}~\includegraphics[width=0.19\linewidth]{img/20131020-b}~\includegraphics[width=0.19\linewidth]{img/20131021-b}~\includegraphics[width=0.19\linewidth]{img/20131022-b}
	%\vspace{-0.2cm}
	\caption{Progression de l'OSE observé entre le 18 et le 22 Octobre 2013}\label{fig:progression}
\end{figure}

Nous avons aussi comparé les coordonnées des OSE par rapport aux données de vorticité potentielle, l'un des facteurs étudiés par Peres. Afin de ne pas surcharger l'image, nous avons tracé seulement les points situés à proximité de l'observatoire de Santa Maria (Brésil). Comme montrent les cartes dans la Figure \ref{fig:comparison}, on observe une forte corrélation entre la vorticité potentielle et l'approximation des masses d'air pauvres en Ozone, spécialement sur la carte du 20 octobre.  On peut aussi observer que ces OSE prennent du temps à se dissiper : même si la vorticité potentielle s'est déplacée, une poche pauvre en Ozone persiste sur une zone habitée deux jours plus tard. Ces résultats encouragent la poursuite de l'étude de la corrélation entre les OSE et la vorticité potentielle.


\begin{figure}
	\centering
	\includegraphics[width=0.75\linewidth]{img/comparison2}
	%\vspace{-0.2cm}
	\caption{Superposition des cartes de la vorticité potentielle et le OSE identifié sur l'observatoire de Santa Maria, Brésil (29.68 S, 53.81 W)}\label{fig:comparison}
\end{figure}

La scalabilité de l'application a aussi été étudiée car cet algorithme peut être utilisé autant pour des détections journalières que pour des analyses plus poussées sur des périodes ou zones plus importantes. Ainsi, par exemple, l'analyse de la période entre le 15 et le 31 octobre 2013 a été fait dans une \textit{cluster} pervasif composé de seulement deux machines (un Macbook Air  - Intel i7-4650U, 2 c{\oe}urs, 8GB RAM -  et un Dell Precision T5610 - 2x Intel Xeon E5-2620, 12 c{\oe}urs, 32GB RAM). 

En utilisant l'ensemble des c{\oe}urs de calcul de chaque machine, l'analyse a duré 570 secondes. En comparaison, l'évaluation d'une seule journée avec un Raspberry Pi 2 a nécessité 40 minutes. Ceci peut être optimisé en augmentant le nombre de coordonnées traitées par chaque tâche (réduisant le surcout du démarrage d'une nouvelle tâche) mais aussi on en rajoutant d'autres n{\oe}uds au \textit{cluster} pervasif.  %Malgré leur faible performance, l'usage de dispositifs bas de gamme comme les Raspberry Pi reste une alternative économique et suffisante pour certains types de tâches, comme le prétraitement et la détection à partir des données journalières. Si par contre nous avons besoin d'explorer un grand ensemble de données historiques, des machines plus puissantes peuvent être allouées à des communautés CloudFIT dédiées à ces tâches plus lourdes. 

\section{Travaux en Cours et Perspectives}

%Au travers les différentes expérimentations, l'intergiciel CONFIIT a prouvé son efficacité et sa stabilité. Afin de répondre aux attentes de clients potentiels, je développe actuellement de nouvelles fonctionnalités, et envisage la mise en place d’éléments de sécurité.

Le développement de CloudFIT occupe une place important dans ma recherche du fait de pouvoir l'enrichir avec des nouvelles techniques issues de mes travaux de recherche. Ainsi, au delà de la consolidation du réseau multi-échelle et de la mise en place de la \textit{data-locality} discutés en sections \ref{sec:multiechelle} et \ref{sec:datalocality}, je compte développer CloudFIT dans le cadre des collaborations suivantes : 


\subsubsection*{Plateforme pour la détection et la prédiction des OSE}

Comme indiqué en Section \ref{subsec:ozone}, CloudFIT a été utilisé lors de la préparation du du projet international CAPES-Cofecub MESO. Les travaux autour de la détection et la prédiction des OSE doivent se poursuivre dans les années à venir, et dans un premier moment je vais accueillir deux chercheurs brésiliens à Reims, à partir de l'hiver 2017 (une doctorante en co-tutelle et un post-doctorant). Ces chercheurs, spécialisés dans le domaine de la météorologie, auront notamment pour mission la création des modèles atmosphériques spécifiques pour les conditions de la stratosphère, utilisant par exemple le modèle WRF \cite{Skamarock08a}. 

Un autre objectif de ces missions est celui de développer un environnement de calcul à faible coût pour l'exécution de ces modèles atmosphériques. L'approche privilégiée est celle des \textit{clusters} de nano-ordinateurs, pour des raisons telles que le faible coût d'achat et de maintenance. Pour cela, on envisage d'associer des machines virtuelles de type conteneur avec CloudFIT, ce dernier jouant le rôle de gestionnaire de tâches et des ressources.   

De même, nous étudions les possibilités d'utilisation et de déploiement de capteurs UV de la gamme ML8511 ou similaire pour l'établissement d'un réseau de surveillance "bas coût" des variations de la radiation UV. L'intégration des données issues de ces dispositifs IoT à la plate-forme de calcul permettra une meilleure couverture des événements liés à la couche d'Ozone Antarctique, notamment dans les zones plus proches des tropiques qui ne sont pas totalement couvertes par l'orbite des satellites.


\subsubsection*{Ordonnancement sensible au contexte, déploiement et migration de micro-services  dans un environnement \textit{fog computing}}

Le \textit{fog computing} est un concept qui englobe plusieurs définitions à la fois. L'un des principaux défis est celui de garder toute la flexibilité et la disponibilité du \textit{cloud} au même temps où l'on cherche à placer les services au plus près des utilisateurs, en utilisant l'ensemble de ressources qui l'entourent. De ce fait, il est difficile de concevoir un système répondant à tous ces critères, mais on peut essayer de répondre à quelques uns.

Les sections précédentes ont montré certaines fonctionnalités de CloudFIT qui peuvent être mis au service de la recherche sur les réseaux hétérogènes dont le \textit{fog}. 
Plus qu'une démarche d'ingénieur, l'utilisation de CloudFIT donne des outils pour la recherche, qui autrement ne serait que conceptuelle (comme c'est encore le cas de plusieurs travaux sur le \textit{fog}) ou dépendante de technologies tiers.

Ainsi, je souhaite continuer à faire évoluer la plateforme dans le but de fournir les outils pour cette recherche. Parmi les priorités, il y a bien sûr la poursuite des travaux sur l'ordonnancement sensible au contexte. Les outils de base sont déjà en place (collecteur de contexte, ordonnanceur simple) mais les cas étudiés jusqu'à présent n'ont pas encore été suffisamment poussés pour permettre des grandes avancées dans ce domaine. 

De même, l'organisation multi-échelle des ressources me semble essentielle pour le passage à l'échelle nécessaires à ces environnements. Si les promesses du \textit{fog computing} se réalisent, celui-ci sera amené à intégrer des ressources allant de l'IoT au \textit{cloud}, ce qui serait impossible à gérer sans une organisation modulaire des ressources.  
 
Finalement, je compte investir dans le support aux machines virtuelles (et les micro-services) car, contrairement aux applications actuellement supportées, celles-ci permettent une migration plus facile des tâches. Sans le support à la migration, les stratégies d'ordonnancement sensibles au contexte développées sur CloudFIT resteraient incapables d'attaquer des problèmes essentiels comme l'équilibrage de charge, la minimisation des temps de réponse, etc. 

% !TeX spellcheck = fr_FR

La définition du mot \textbf{hétérogénéité} donné par le Dictionnaire Larousse ("\textit{Manque d'unité, composé d'éléments de nature diverse}") n'est pas suffisamment développée pour qualifier les différents défis liés à l'hétérogénéité dans les systèmes et applications distribués. Afin de mieux comprendre ces défis, il est important d'identifier et de cataloguer les différents mécanismes liés à l'hétérogénéité.

Une première catégorie est issue directement de la définition simple ci-dessus, et représente les variations des équipements composant un système informatique. Sous cette optique, l'hétérogénéité se présente comme une conséquence de la différente construction des dispositifs qui composent le système, notamment leur composition matérielle (processeurs, mémoire) et leur capacité de calcul. Ainsi, un système distribué composé d'équipements identiques (caractérisé par l'absence d'hétérogénéité matérielle) peut supposer un traitement uniforme des tâches de calcul et de traitement de données, et donc simplifier la gestion des applications qu'y tournent. Au contraire, un système composé par des équipements hétérogènes, même partiellement, doit être conscient de cette différence et prévoir des mécanismes pour garantir l'exécution des applications : synchronisation des tâches dépendantes, ordonnancement selon les capacités des équipements, équilibrage et migration de charge, etc.  Même étant très réductrice, \textit{l'hétérogénéité matérielle} est souvent utilisée pour qualifier des équipements : machines parallèles (symétriques), clusters (grappes d'ordinateurs), grids (grilles de calcul), cloud, réseaux ad-hoc et P2P, etc.

À l'hétérogénéité matérielle s'ajoute le problème de l'\textit{hétérogénéité des communications}, qui peut être causé autant par la diversité matérielle (par exemple, en utilisant différentes technologies réseau) ou par la distance géographique (qui impacte les temps de communication). On retrouve l'hétérogénéité des communications surtout dans les systèmes distribués à grande échelle (grids, réseaux P2P) où le temps de communication devient un facteur non négligeable. La prise en charge de l'hétérogénéité des communications se fait notamment par l'optimisation des dépendances : limitation des communications sur les grandes distances,  recouvrement des communications par de calculs, ordonnancement basé sur la topologie du réseau, etc. Toutefois, cette prise en charge ne peut pas se faire sans une connaissance des facteurs impactant la communication, d'où la nécessité de mesurer et modéliser les communications. 

Il est claire que la diversité matérielle et la diversité des communications (matérielle ou spatiale) constituent les facteurs les plus importants liés à l'hétérogénéité à un moment donné de l'exécution d'une application, toutefois ce ne sont pas les seuls éléments impactant le déroulement de son exécution. Plus qu'assurer des bonnes conditions à un moment ou opération précis, nous devons garantir le fonctionnement d'un système distribué malgré les variations qu'il subit pendant la durée de son fonctionnement. Cette forme d'hétérogénéité "\textit{temporelle}" est issue de la dynamicité de l'opération d'un système. Plus exactement, les systèmes distribués peuvent être impactés par le départ ou l'arrivé de ressources, mais aussi par leur changement d'état ou de capacité. De ce fait, la prise en compte de ces facteurs devient essentiel pour le bon fonctionnement d'un système et d'une application. La prise en charge de la dynamicité implique plusieurs éléments : la surveillance des ressources et la détection des pannes/états invalides, le suivi et la récupération des tâches attribuées à des éléments disparus et aussi le rééquilibrage de charge dans le cas d'une augmentation des ressources disponibles. En effet, la dynamicité affecte l'utilisation des ressources, car même sans une défaillance un système doit pouvoir être amené à gérer plusieurs tâches indépendantes, chacune avec des besoins propres.

D'un point de vue applicatif, nous pouvons aussi rencontrer des difficultés avec une tout autres catégorie d'hétérogénéité, transversale aux trois précédentes :\textit{ l'hétérogénéité des données}. En effet, le développement d'une application est souvent guidé par la manière dont on accède aux données, et le \textit{big data} a mis en évidence le besoin de gérer non seulement des grandes volumes de données mais surtout leur variété. Les données peuvent se présenter sous des abstractions bien connues comme par exemple les objets dans la mémoire, les fichiers, les URIs ou les requêtes distantes (RPC, web services, etc.). Toutefois, il est rare qu'une application dispose d'un accès uniforme à tout type de donnée, ce qui implicitement introduit de l'hétérogénéité au niveau de l'accès aux données et à leur traitement. 

Mon travail de recherche s'inscrit donc dans la gestion de l'hétérogénéité, sous ses différentes facettes. En navigant entre ces aspects, j'ai pu travailler à la fois sur la tolérance aux fautes, la modélisation des performances, l'adaptation au contexte et l'ordonnancement, et même la spécification et développement d'intergiciels (\textit{middlewares}) pour le calcul distribué. Bien souvent j'ai pu profiter des collaborations et projets dont j'ai été membre ou responsable pour introduire ou explorer des éléments liés à la gestion de l'hétérogénéité, tout comme dans les thèses de doctorat que j'ai co-encadré. 

Ce mémoire présente une partie de ces contributions, toutes ayant fait l'objet de publications dans des journaux et conférences internationaux, mais aussi d'autres communications qui se trouvent sur la liste récapitulative à la fin de cet ouvrage. Le mémoire est organisé en cinq parties, dans lesquelles j'expose les différents aspects de mes travaux de recherche visant la gestion de d'hétérogénéité :
\begin{description}
	\item[i] l'évaluation et la modélisation des performances de communication dans les grids; 
	\item [ii] la parallélisation et la gestion de l'hétérogénéité des tâches ;
	\item [iii] l'adaptation à la dynamicité des ressources de calcul ;
	\item [iv] la spécification d'une plate-forme pair-à-pair visant l'accès à différentes sources de données ;
	\item [v] la conception et le développement d'un intergiciel pair-à-pair pour le calcul distribué dans des environnements hétérogènes tels que le \textit{fog computing} et l'Internet des Objets.
\end{description}


Dans la première partie, je présente des algorithmes originaux issus des travaux menés à la fin de ma thèse et dans les trois années subséquentes. Ces travaux visaient notamment la compréhension des facteurs impactant les opérations de communication collective dans les grids de calcul, et dont le but ultime était à la fois d'optimiser ces opérations mais aussi de pouvoir estimer leur performance avec haute précision.  J'exploite ainsi des méthodes de mesure de performance et de découverte de la topologie réseau afin de représenter correctement les environnements et pouvoir extraire des indicateurs aidant à choisir les algorithmes de communication collective les plus adaptés à chaque situation. 

Dans la deuxième partie j'illustre les efforts pour la parallélisation et la gestion de l'exécution distribuée d'une application métier en biochimie. Ce travail a été développé dans le cadre du co-encadrement de thèse de doctorat de Romain Vasseur (thèse CIFRE en collaboration avec le Laboratoire MeDyC - Matrice Extracellulaire et Dynamique Cellulaire - UMR CNRS 7369 et la compagnie Bull-Atos), et visait le développement de stratégies HPC pour le \textit{docking inversé}, une technique de simulation des interactions biomoléculaires. Comme il n'était pas envisageable de paralléliser le code source de l'application, nous avons opté par le développement de stratégies visant à découper convenablement l'espace de recherche et permettre le traitement parallèle des tâches de calcul. Ceci a été accompagné par le développement d'une plate-forme de déploiement capable de gérer l'exécution des tâches distribuées sur plusieurs n{\oe}uds ou bien de tirer profit des gestionnaires de tâches présents sur la plupart des clusters HPC. 

La troisième partie de ce mémoire s'attaque à la dynamicité des ressources et aux stratégies pour s'adapter à ces changements. Plus exactement, on reprend une partie des travaux effectués pendant le projet STIC-AmSud PER-MARE dans lequel nous avons apporté des améliorations à la plate-forme \textit{big data} Apache Hadoop afin de la rendre compatible avec des environnements hétérogènes et dynamiques (environnements pervasifs). Grâce à un mécanisme de collecte d'informations sur le contexte des ressources de calcul, nous avons modifié l'ordonnanceur de Hadoop afin d'adapter le lancement de tâches aux ressources disponibles à chaque instant. Outre la présentation du mécanisme de collecte de contexte et des stratégies d'intégration à Hadoop, cette partie inclut des \textit{benchmarks} démontrant l'efficacité des solutions proposées. 

La quatrième partie présente la spécification d'une plate-forme distribuée pour la gestion universelle de données, résultat do co-encadrement de la thèse de doctorat de Thierno Ahmadou Diallo (thèse en co-tutelle avec l'Université Cheikh Anta Diop, Sénégal). La motivation pour ce travail a été celle de créer une base documentaire indépendante de la nature des données (fichiers, flux, bases de données, etc.) et qui pourrait être utilisée par les universités et écoles de l'Afrique, dans lesquelles l'accès au cloud n'est pas toujours évident à cause des vitesses d'interconnexion. Dans ce travail je présente seulement la partie dédiée à la spécification de la plate-forme GRAPP\&S, le cas d'usage retenu pendant la thèse (utilisation de la plate-forme pour pour le \textit{e-learning}) n'étant pas d'intérêt direct pour ce mémoire. 

Finalement, la cinquième partie introduit la plate-forme de calcul distribué CloudFIT. Développée initialement dans le cadre du projet STIC-AmSud PER-MARE, CloudFIT s'est révélé une excellente plate-forme expérimentale pour le prototypage et le test de techniques pour le \textit{fog computing} et l'Internet des Objets. Dans un premier moment nous présentons l'architecture et les mécanismes de communication et de gestion des n{oe}uds. Par la suite, on introduit des stratégies pour l'ordonnancement adapté au contexte nécessaires au support à des ressources de calcul très hétérogènes, allant des dispositifs IoT aux datacenters et cloud. Cette variété de ressources et un élément clé du \textit{fog computing}, que nous embrassons en proposant des stratégies pour la structuration multi-échelle du réseau ou bien de techniques pour renforcer la \textit{data-locality}. Cette partie se termine par la présentation de deux travaux où CloudFIT a été utilisé en tant que plate-forme de calcul. Dans le premier cas, il s'agit de l'exécution d'une application \textit{big data} bien connue. Dans le deuxième cas, nous présentons la spécification et l'implémentation d'une application en physique de l'atmosphère destinée à la surveillance d'événements liés à la couche d'Ozone Antarctique. 

Je conclurai enfin ce document en présentant les perspectives de recherche que j'espère pouvoir développer dans un avenir proche.


 


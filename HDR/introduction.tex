% !TeX spellcheck = fr_FR

La définition du mot \textbf{hétérogénéité} donné par le Dictionnaire Larousse ("\textit{Manque d'unité, composé d'éléments de nature diverse}") n'est pas suffisamment développée pour qualifier les différents défis liés à l'hétérogénéité dans les systèmes et les applications distribués. Afin de mieux comprendre ces défis, il est important d'identifier et de cataloguer les différents mécanismes liés à l'hétérogénéité.

Une première catégorie représente les variations des équipements composant un système informatique. Sous cette optique, l'hétérogénéité se présente comme une conséquence de la différente construction des dispositifs qui composent le système, notamment leur composition matérielle (processeurs, mémoire) et leur capacité de calcul.   Même étant très réductrice, \textit{l'hétérogénéité matérielle} est souvent utilisée pour qualifier des équipements : machines parallèles (symétriques), \textit{clusters} (grappes d'ordinateurs), \textit{grids} (grilles de calcul), infrastructures \textit{cloud}, réseaux \textit{ad-hoc} et pair-à-pair (P2P), etc.

À l'hétérogénéité matérielle s'ajoutent les problèmes de l'\textit{hétérogénéité des tâches} et de l'\textit{hétérogénéité des communications}. L'\textit{hétérogénéité des tâches} résulte soit d'une différence matérielle, soit d'une distribution déséquilibré de charge entre les différents ressources participant à un calcul. La prise en charge de l'hétérogénéité des tâches dépend beaucoup des contraintes du système ou de l'application, telles que la présence de dépendances entre les tâches ou bien des contraintes sur le temps d'exécution (Qualité de Service).

Dans le cas de l'hétérogénéité des communications, les variations peuvent être causées autant par la diversité matérielle (par exemple, en utilisant différentes technologies réseaux) que par la distance géographique (qui impacte les temps de communication). On retrouve l'hétérogénéité des communications surtout dans les systèmes distribués à grande échelle (\textit{grids}, réseaux P2P, etc.) où le temps de communication devient un facteur non négligeable. La prise en charge de l'hétérogénéité des communications se fait notamment par l'optimisation des dépendances : limitation des communications sur les grandes distances,  recouvrement des communications par de calculs, ordonnancement basé sur la topologie du réseau, etc. Toutefois, cette prise en charge ne peut pas se faire sans une connaissance des facteurs impactant la communication, d'où la nécessité de mesurer et de modéliser les communications. 

Il est clair que la diversité matérielle et la diversité des communications (matérielle ou spatiale) constituent les facteurs les plus importants lors de l'exécution d'une application. Toutefois, il faut également assurer le fonctionnement d'un système distribué au travers des variations qu'il subit pendant toute la durée de son exécution. Cette forme d'hétérogénéité "\textit{temporelle}" est issue de la dynamique de l'exécution d'un système. Plus exactement, les systèmes distribués peuvent être impactés par le départ ou l'arrivé de ressources, mais aussi par leur changement d'état ou de capacité. De ce fait, la prise en compte de ces facteurs devient essentielle pour le bon fonctionnement d'un système ou d'une application. La prise en charge de la dynamicité implique plusieurs éléments : la surveillance des ressources et la détection des pannes/états invalides, le suivi et la récupération des tâches attribuées à des éléments disparus et aussi le rééquilibrage de charge dans le cas d'une augmentation des ressources disponibles. En effet, la dynamicité affecte l'utilisation des ressources, car même sans une défaillance un système doit pouvoir être amené à gérer plusieurs tâches indépendantes, chacune avec des besoins propres.

D'un point de vue applicatif, on peut également rencontrer des difficultés avec une tout autre catégorie d'hétérogénéité, transversale aux trois précédentes : \textit{l'hétérogénéité des données}. En effet, le développement d'une application est souvent guidé par la manière dont on accède aux données, et le \textit{big data} a mis en évidence le besoin de gérer non seulement des grands volumes de données mais surtout leur variété. Les données peuvent se présenter sous des abstractions bien connues comme par exemple les objets dans la mémoire, les fichiers, les URIs ou les requêtes distantes (RPC, Web services, etc.). Toutefois, il est rare qu'une application dispose d'un accès uniforme à tout type de donnée, ce qui implicitement introduit de l'hétérogénéité au niveau de l'accès aux données et à leur traitement. 

Mon travail de recherche s'inscrit donc dans la gestion de l'hétérogénéité, sous ses différentes facettes. En naviguant entre ces aspects, j'ai pu travailler à la fois sur la tolérance aux fautes, la modélisation des performances, l'adaptation au contexte et l'ordonnancement, et même la spécification et le développement d'intergiciels (\textit{middlewares}) pour le calcul distribué. Bien souvent j'ai pu profiter des collaborations et des projets dont j'ai été membre ou responsable pour introduire ou explorer des éléments liés à la gestion de l'hétérogénéité, tout comme dans les thèses de doctorat que j'ai co-encadré. 

Ce mémoire présente une partie de ces contributions, toutes ayant fait l'objet de publications dans des journaux et des conférences internationaux, mais aussi d'autres communications qui se trouvent sur la liste récapitulative à la fin de cet ouvrage. Le mémoire est organisé en cinq parties, dans lesquelles j'expose les différents aspects de mes travaux de recherche visant la gestion de d'hétérogénéité :
\begin{description}
	\item[i] l'évaluation et la modélisation des performances de communication dans les \textit{grids} ; 
	\item [ii] la parallélisation et la gestion de l'hétérogénéité des tâches ;
	\item [iii] l'adaptation à la dynamicité des ressources de calcul ;
	\item [iv] la spécification d'une plateforme pair-à-pair visant l'accès à différentes sources de données ;
	\item [v] la conception et le développement d'un intergiciel pair-à-pair pour le calcul distribué dans des environnements hétérogènes tels que le \textit{fog computing} et l'Internet des Objets.
\end{description}


Dans la première partie, je présente des algorithmes originaux issus des travaux menés à la fin de ma thèse et dans les trois années subséquentes. Ces travaux visaient notamment la compréhension des facteurs impactant les opérations de communication collective dans les \textit{grids}, et dont le but ultime était à la fois d'optimiser ces opérations mais aussi de pouvoir estimer leur performance avec une haute précision.  J'exploite ainsi des méthodes de mesure de performance et de découverte de la topologie réseau afin de représenter correctement les environnements et pouvoir extraire des indicateurs aidant à choisir les algorithmes de communication collective les plus adaptés à chaque situation. 

Dans la deuxième partie j'illustre les efforts pour la parallélisation et la gestion de l'exécution distribuée d'une application métier en biochimie. Ce travail a été développé dans le cadre du co-encadrement de thèse de doctorat de Romain Vasseur (thèse CIFRE en collaboration avec le Laboratoire MeDyC - Matrice Extracellulaire et Dynamique Cellulaire - UMR CNRS 7369 et la compagnie Bull-Atos), et visait le développement de stratégies HPC pour le \textit{docking inversé}, une technique de simulation des interactions biomoléculaires. Comme il n'était pas envisageable de paralléliser le code source de l'application, nous avons opté par le développement de stratégies visant à découper convenablement l'espace de recherche et permettre le traitement parallèle des tâches de calcul. Ceci a été accompagné par le développement d'une plateforme de déploiement capable de gérer l'exécution des tâches distribuées sur plusieurs n{\oe}uds ou bien de tirer profit des gestionnaires de tâches présents sur la plupart des \textit{clusters} HPC. 

La troisième partie de ce mémoire s'attaque à la dynamique des ressources et aux stratégies pour s'adapter à ces changements. Plus exactement, je reprends une partie des travaux effectués pendant le projet STIC-AmSud PER-MARE dans lequel nous avons apporté des améliorations à la plateforme \textit{big data} Apache Hadoop afin de la rendre compatible avec des environnements hétérogènes et dynamiques (environnements pervasifs). Grâce à un mécanisme de collecte d'informations sur le contexte des ressources de calcul, l'ordonnanceur de Hadoop a été modifié  afin d'adapter le lancement de tâches aux ressources disponibles à chaque instant. Outre la présentation du mécanisme de collecte de contexte et des stratégies d'intégration à Hadoop, cette partie inclut des \textit{benchmarks} démontrant l'efficacité des solutions proposées. 

La quatrième partie présente la spécification d'un réseau hiérarchique pour la gestion universelle de données, résultat du co-encadrement de la thèse de doctorat de Thierno Ahmadou Diallo (thèse en cotutelle avec l'Université Cheikh Anta Diop, Sénégal). La motivation pour ce travail a été celle de créer une base documentaire indépendante de la nature des données (fichiers, flux, bases de données, etc.) et qui pourrait être utilisée par les universités et les écoles en Afrique, dans lesquelles l'accès aux infrastructures de type \textit{cloud} ne sont pas toujours évidentes à cause des vitesses d'interconnexion. Dans ce travail je présente seulement la partie dédiée à la spécification de la plateforme GRAPP\&S, le cas d'usage retenu pendant la thèse (utilisation de la plateforme pour le \textit{e-learning}) n'étant pas d'intérêt direct pour ce mémoire. 

Finalement, la cinquième partie introduit la plateforme de calcul distribué CloudFIT. Développée initialement dans le cadre du projet STIC-AmSud PER-MARE, CloudFIT s'est révélé une bon outil pour le prototypage et le test de techniques pour le \textit{fog computing} et l'Internet des Objets (\textit{Internet of Things} - IoT). Dans un premier moment je présente l'architecture et les mécanismes de communication et de gestion des n{oe}uds. Par la suite, j'introduis des stratégies pour l'ordonnancement adapté au contexte pour les ressources de calcul très hétérogènes, allant des dispositifs IoT aux \textit{data centers} et infrastructures sur le \textit{cloud}. Cette variété de ressources est un élément clé du \textit{fog computing}, que j'aborde en proposant des stratégies pour la structuration multi-échelle du réseau ou bien de techniques pour renforcer la \textit{data-locality}. Cette partie se termine par la présentation de deux travaux où CloudFIT a été utilisé en tant que plateforme de calcul. Dans le premier cas, il s'agit de l'exécution d'une application \textit{big data} bien connue. Dans le deuxième cas, je présente la spécification et l'implémentation d'une application en physique de l'atmosphère destinée à la surveillance d'événements liés à la couche d'Ozone Antarctique. 

Je conclurai enfin ce document en présentant les perspectives de recherche que j'espère pouvoir développer dans un avenir proche.


 


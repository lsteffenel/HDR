\documentclass[a4paper]{book}
\usepackage[T1]{fontenc}

%\usepackage[latin1]{inputenc} 
\usepackage[francais]{babel}

\usepackage{graphicx}

\begin{document}

\chapter{Résumé des Activités de Recherche}

Tout au long de ma vie académique et professionnelle, mes travaux de recherche ont été orientés sur le développement et l'amélioration des systèmes distribués. Malgré les différents champs d'application (tolérance aux fautes, calcul distribué, traitement de masses de données), ces travaux on toujours eu pour ligne conductrice l'adaptation à l'hétérogénéité. En effet, l'hétérogénéité (des ressources, des communications, des calculs, des données, des besoins, etc.) est un facteur qui rend les systèmes à la fois plus complexes et moins fiables. Dans ce résumé d'activités je présente un aperçu des domaines où j'ai pu collaborer et qui sont marqués par l'hétérogénéité. 

\section{Prise en compte de l'hétérogénéité au niveau du réseau}

\subsection{La découverte de la topologie}

La découverte de topologie d'un réseau a un rôle très significatif dans mon travail, car cela permet l'identification des facteurs qui rendent un réseau hétérogène. Cette identification est très importante, une fois que la présence d'hétérogénéités augmente la complexité des modèles et réduit la précision des prédictions de performance. L'identification des la topologie permet aussi une meilleure distribution des données et tâches de calcul, des éléments essentiels lors de l'expérimentation sur des environnements à grande échelle. 

Plusieurs approches peuvent être utilisées pour la découverte de la topologie d'un réseau. Dans certains cas, les propriétés individuelles des composants du réseau sont suffisantes pour caractériser le réseau mais, dans la plupart du temps, ces propriétés ne sont pas suffisamment représentatives pour qu'on puisse établir un modèle réaliste des communications. Pour cette raison, lors des travaux effectués dans le cadre de la bibliothèque LaPIE \ref{Steffenel05}, j'ai dû développer un outil propre de découverte de topologie, mélangeant à la fois des techniques traditionnelles et des techniques de mesure de performance. Cette méthodologie, spécialement adaptée à la modélisation des applications parallèles, permet la découverte des caractéristiques du réseau dans toute son extension, avec une analyse très pragmatique des aspects qualitatifs et quantitatifs des interconnexions réseau.

\subsection{La modélisation des performances}

Les contributions dans le domaine de la modélisation de performance portent notamment sur le développement et la validation de modèles de coût pour les opérations de communication collective, i.e., des schémas de communication qui concernent plus de deux interlocuteurs. Parmi les différentes opérations de communication collective, je me suis intéressé aux trois patrons de communication les plus représentatifs, Un vers Plusieurs (\textit{Broadcast/Multicast}), Un vers Plusieurs Personnalisé (\textit{Scatter}) et Plusieurs vers Plusieurs Personnalisé (\textit{All-to-All}). 

Dans le cas des patrons Un vers Plusieurs et Un vers Plusieurs Personnalisé, les efforts se sont concentrés sur l'étude des différentes stratégies de communication et le développement de modèles de performance capables de représenter correctement le fonctionnement de ces stratégies. Pour cela, j'ai développé des modèles mathématiques qui, associés aux paramètres de communication obtenus lors de la découverte de topologie, permettent l'obtention d'estimations de performance avec une qualité supérieure à celle des modèles existants précédemment. Afin de valider ces modèles, j'ai effectué plusieurs campagnes de mesure et comparaison sur différents environnements réseaux, et sur différentes architectures informatiques.
     
Dans le cas du patron de communication Plusieurs vers Plusieurs Personnalisé, par contre, nous avons constaté que seul les paramètres de communication ne suffisent pas à l'estimation des temps de communication, du fait que ce patron génère un très important échange de messages entre les interlocuteurs, occasionnant de la congestion au niveau du réseau. L'observation de ce phénomène m'a poussé à l'étude de l'impact de la congestion et à l'adaptation des modèles de performance selon la charge du réseau, de manière à les rendre plus précis et efficaces mais sans pour autant augmenter la complexité du modèle.

\subsection{La clusterisation des ressources et la mise en place de mécanismes pour une communication hiérarchique}

Si les travaux sur découverte de la topologie et la modélisation des communications cités dans les sections précédentes permettent une meilleure compréhension des facteurs qui rendent un réseau hétérogène, ils est toutefois évident qu'une variation trop importante de ces paramètres rend trop complexe l'estimation des performances réseau. Au lieu de développer des modèles complexes adaptés à des situation beaucoup trop spécifiques, une partie de mes travaux s'est orienté sur la clusterisation des ressources, afin de construire des mécanismes de communication hiérarchisé susceptibles d'être modélisés avec une bonne précision et une faible complexité.   

Parmi les environnements hétérogènes, je me suis intéressé par les grilles de calcul, des environnements composés par l'association de plusieurs équipements de calcul (des cluster ou grappes de calcul) dont les capacités et caractéristiques présent peu de variation interne mais une forte variation entre différentes grappes.  Ces variations de performance représentent un défi pour l'établissement et coordination efficace des communications, une fois que la complexité des réseaux empêche l'élaboration de modèles de performance adaptés à chaque grille de calcul. 

Afin de compenser les impacts de l'hétérogénéité sur les communications entre les applications, la plupart des approches traditionnelles que j'ai étudié étaient fondées sur le simple principe de la séparation entre communications locales et distantes, dans un modèle simpliste à deux couches et qui est malheureusement loin d'être optimale. L'objectif de mes recherches, au contraire, visait l'étude de stratégies pour utiliser la connaissance sur la topologie du réseau et la modélisation des performances de manière à construire des structures de communication hiérarchiques qui atteignent des performances élevées sans pour autant perdre en simplicité. Pour cette raison, les travaux dans le cadre de l'adaptation des communications sur les environnements des grilles de calcul combinaient à la fois la modélisation des performances et l'étude de techniques d'ordonnancement des communications, grâce à des heuristiques d'optimisation.

 En effet, j'ai travaillé sur l'hypothèse que les communications sur les grilles de calcul peuvent être organisées en plusieurs couches hiérarchiques dynamiquement organisées. À partir de cet hypothèse, j'ai cherché des heuristiques efficaces pour l'ordonnancement des communications. À l'aide de simulations et expériences pratiques, le fonctionnement de différentes heuristiques a été comparé, à la recherche de stratégies d'optimisation de communication à la fois efficaces et robustes. Cette analyse a permis notamment l'identification des facteurs qui affectent plus l'ordonnancement des communications, ce qui a permis le développement de nouvelles heuristiques plus adaptées aux besoins des grilles de calcul.


\subsection{Détection de changements topologiques à cause de la volatilité des ressources}
  
Dans tous les systèmes distribués, la fiabilité et la tolérance aux fautes sont des facteurs essentiels au bon fonctionnement d'un système. Selon la nature des applications, des niveaux différents de fiabilité sont nécessaires, allant de la simple vérification d'une transmission à la coordination de l'ensemble d'acteurs. Le choix des techniques les plus appropriées à chaque type d'application est donc déterminé par des éléments tels que l'environnement d'exécution et le niveau de fiabilité requis, mais aussi par la performance des solutions vis-à-vis la taille des problèmes et des systèmes.


L'un des premiers défis réside en détecter les défaillances, afin de pouvoir agir par la suite, si nécessaire. Le postulat dit "Impossibilité FLP" (nommé en raison de ses auteurs, Fischer, Linch et Paterson) démontre que dans les systèmes distribués asynchrones il est impossible de faire la distinction entre un processus défaillant (ou noeud, s'il s'agit d'une machine physique) et un processus qui est simplement trop lent à répondre. Fort heureusement telle impossibilité peut être contournée dans les réseaux informatiques habituels, car ils ne sont pas totalement asynchrones : en utilisant les spécifications des réseaux et des indices système, il est possible établir des estimations approximatives sur les bornes de communication et ainsi prévoir avec un certain marge d'erreur quel est l'état courant d'un processus distant. Si utilisés correctement, ces détecteur permettent aux différents algorithmes de tolérance aux fautes de sortir des situations de blocage (\textit{liveness}), tout en préservant la consistance des informations (\textit{safety}).

Les détecteur de défaillance sont donc des mécanismes implémentés sous la forme de sondes actives ou passives et qui ont pour but la surveillance de l'activité des processus, afin de pouvoir offrir une estimation sur l'état des noeuds lorsqu'une décision s'impose. Ces mécanismes peuvent être implémentés au sein même des algorithmes ou en tant que module à part, mais son rôle est toujours celui de donner des indices sur l'état actuel des machines. Dans [STEFF] je me suis intéressé au problème de la spécification des détecteurs de défaillance et à l'analyse de leur précision/performance vis-à-vis les différentes possibilités d'implémentation. En effet, la littérature classique sur le thème a permis la définition de deux modèles de base, l'un passif (Push) et l'autre actif (Pull), mais ces modèles ont rarement été analysés d'un point de vue pratique, i.e., en considérant la fiabilité des estimations, le temps de réaction, la surcharge du réseau et le passage à l'échelle. Dans [STEFF] j'ai pu mener des analyses sur ces facteurs dans le cadre d'une utilisation avec le problème du consensus distribué, ce qui a permis l'élaboration d'un cahier de recommandation selon le type de environnement envisagé. 

\section{Mécanismes de support à la communication dans les environnements hétérogènes}


Dans le travail précédent j'ai pu aussi constater que les détecteurs de défaillances sont d'autant plus efficaces qu'ils sont intégrés au coeur du fonctionnement des algorithmes qui ont besoin de ce type de recommandation. Ainsi, par la suite je me suis intéressé au problème de la diffusion totalement ordonnée. La littérature propose généralement trois modèles pour la gestion distribuée de données : le modèle transactionnel, le modèle par accord distribué (consensus) et le modèle par vues synchrones. Les deux premiers modèles sont généralement peu performants car ils imposent un accord sur chaque donnée échangée, alors que le troisième modèle parvient à offrir des meilleurs résultats grâce à une utilisation d'un décideur centralisé (primary-backup) et d'un groupe qui fait appel au consensus uniquement lorsqu'un événement requiert le changement de la vue du système. Dans la pratique, toutefois, le modèle en vue synchrone est parfois difficile à implémenter et peut induire à des inconsistances si mal utilisé. Afin de proposer une solution alternative au mécanisme des vues synchrones, j'ai proposé un modèle mixte adapté à la diffusion totalement ordonnée, basé à la fois sur les détecteurs de défaillance, sur un petit groupe de noeuds fortement synchronisés et sur le concept de vues intermédiaires, ce qui permet un meilleur passage à l'échelle du système tout en gardant la consistance et la réactivité face aux pannes.      

%% Confiit ? anneaux, jetons, terminaison, etc.
%% CloudFIT - P2P
%% PER-MARE - 
%% GRAPPES - Routage 

Le travail effectué à l'UFRGS entre 1999 et 2001 sous encadrement du professeur Ingrid Jansch-Pôrto a porté sur l'étude du paradigme imposé par "l'impossibilité FLP", qui prévient un système totalement asynchrone d'inférer sur l'état des processus (il est impossible de distinguer si un processus est tombé en panne ou s'il est simplement plus lent que les autres processus). Cette impossibilité représente une limitation importante lors du développement d'algorithmes distribués, une fois qu'elle empêche la détection de l'état d'un processus dans un temps fini.

Toutefois, certaines techniques ont été développées afin de contourner cette restriction. En effet, les systèmes réels rarement peuvent être considérés comme totalement asynchrones. Dans la plupart des cas ils existent des limitations temporelles auxquelles nous pouvons utiliser pour déterminer la défaillance des processus. C'est ainsi que Chandra et Toueg ont proposé l'utilisation de détecteurs de défaillance, petits modules indépendants de l'application dont la seule tâche est de garder contact avec d'autres détecteurs et de surveiller les éventuels retards de communication. Pour cela, différentes stratégies ont été élaborées, dont les plus connues sont les modèles « Push » et « Heartbeat ». Dans la stratégie Push, chaque processus demande explicitement aux autres processus s'ils sont encore actifs. Un temporisateur est ainsi déclenché, et si aucune réponse n'arrive dans un temps préétabli (plus grand que le RTT du réseau), ce processus suspecté est rajouté à une liste de processus possiblement défaillants. Dans la stratégie Heartbeat, par contre, chaque processus envoie régulièrement des messages de type «I am alive!», et la détection se fait par rapport à la fréquence de réception de tels messages.

Alors que la liste de processus suspects peut être incorrecte (selon l'impossibilité FLP), elle permet à des algorithmes de consensus de progresser de manière consistante malgré la suspicion de certains processus. Ce qui est encore plus important, c'est que l'algorithme de consensus peut être utilisé comme base pour le développement de différents algorithmes distribués dont la diffusion atomique et l'élection.

C'est à ce point qui nous sommes intéressés par les détecteurs de défaillance. Si d'un côté les détecteurs ont permis le développement d'algorithmes de consensus tolérants aux fautes, aucune recherche n'avait été menée afin de déterminer l'impact de ces détecteurs sur la performance du consensus. En effet, le nombre de messages échangés par les détecteurs est potentiellement important, ce qui peut causer des fortes interférences aux algorithmes qui en dépendent. Nous avons donc procédé à l'analyse de différents modèles de détection de défaillance, établissant de manière expérimentale leur influence sur l'opération de consensus par rapport à des métriques telles que la précision des suspicions, la réactivité en cas de défaillance et la saturation du réseau. Des expériences ont été élaborées afin d'indiquer les méthodes les plus précis et le réglage le plus optimal (par rapport aux caractéristiques du réseau) pour la fréquence d'envoi et les timeouts.
Les résultats de ces travaux ont été le sujet d'un article publié dans une conférence de niveau international et de cinq articles publiés dans des conférences et workshops de niveau national.


Le travail effectué à l'EPFL entre 2001 et 2002 a été fait dans le cadre de l'École Doctorale en Systèmes de Communication. Ces travaux, effectués sous encadrement du professeur André Schiper, ont porté sur l'étude d'algorithmes efficaces pour la diffusion atomique. En effet, après la publication des travaux de Chandra et Toueg (1996), la plupart des chercheurs ont adopté les algorithmes fondés sur le consensus. Le consensus est toutefois une opération assez lourde et peu optimisée par rapport au nombre de messages envoyés. Dans nos recherches, nous avons retrouvé une famille d'algorithmes antérieurs aux travaux de Chandra et Toueg qui avaient certaines caractéristiques intéressantes, notamment par rapport au nombre de messages échangés.

Nous nous sommes intéressés à l'analyse du protocole RBP par rapport à une autre solution de diffusion avec ordre totale, le modèle de réplication Primary Backup+VSC. Comme le View Synchronous Communication (VSC) est une technique largement étudiée, elle présente plusieurs stratégies qui peuvent être utilisées pour améliorer le fonctionnement du protocole RBP. Ainsi, nous avons appliqué la technique dite « modèle des deux visions », qui s'est montrée spécialement intéressante lors de l'exécution dans un environnement hétérogène. C'est à partir de cette analyse que j'ai proposé une nouvelle version de RBP basée sur des détecteurs de défaillance et une organisation hiérarchique des noeuds.

Les résultats de ce travail ont été le sujet d'un article publié dans une conférence de niveau international (EuroPar 2003). Plus récemment j'ai repris le sujet afin d'améliorer sa performance et de le mettre en comparaison avec d'autres travaux similaires. Ce nouveau travail a été publié comme rapport de recherche INRIA.




%% MPI
%% Overlays Confiit/CloudFIT
%% GRAPPES Routage

\section{Support aux Applications Distribuées et HPC}

%%% Confiit/CloudFIT
%%% PER-MARE Hadoop
%%% Docking
%%% Context awareness
%%% GridSecu

\section{Future}

%%% GRAPPES GAIA
%%% CloudFIT

\bibliography{/Users/lsteffenel/Documents/Angelo-Bibdesk.bib}

\end{document}
